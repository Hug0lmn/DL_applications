{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QtPFNL1KiBC"
      },
      "source": [
        "## This code will implement the Seq2seq model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-14T14:33:50.432159Z",
          "iopub.status.busy": "2025-09-14T14:33:50.431934Z",
          "iopub.status.idle": "2025-09-14T14:33:55.265828Z",
          "shell.execute_reply": "2025-09-14T14:33:55.264904Z",
          "shell.execute_reply.started": "2025-09-14T14:33:50.43214Z"
        },
        "id": "sJUYE16vKiBD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from Functions_generation import Decoder_Atten, Encodeur_Atten,generate_a_song_structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V03ZNGsKiBE"
      },
      "source": [
        "## Pipeline comparaison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-14T14:33:55.266969Z",
          "iopub.status.busy": "2025-09-14T14:33:55.266626Z",
          "iopub.status.idle": "2025-09-14T14:33:55.274696Z",
          "shell.execute_reply": "2025-09-14T14:33:55.273631Z",
          "shell.execute_reply.started": "2025-09-14T14:33:55.266948Z"
        },
        "id": "b8-6hanaKiBE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-14T14:33:55.277073Z",
          "iopub.status.busy": "2025-09-14T14:33:55.276753Z",
          "iopub.status.idle": "2025-09-14T14:33:55.316805Z",
          "shell.execute_reply": "2025-09-14T14:33:55.315604Z",
          "shell.execute_reply.started": "2025-09-14T14:33:55.277042Z"
        },
        "id": "Tp3tb0-0KiBF",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with open(r\"..\\Seq2seq\\Files\\Encoding_map.pkl\", \"rb\") as f:\n",
        "    mapping = pickle.load(f)\n",
        "\n",
        "int2char = {i: ch for ch, i in mapping.items()}\n",
        "nb_char = len(int2char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "matrix = pd.read_csv(r\"..\\Markov\\transition_matrix.csv\")\n",
        "\n",
        "states = np.array(matrix.iloc[6])\n",
        "prob_transi = np.array(matrix.iloc[0:6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUSXEt3_KiBJ"
      },
      "source": [
        "## Model loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-09-14T14:33:55.739031Z",
          "iopub.status.busy": "2025-09-14T14:33:55.738653Z",
          "iopub.status.idle": "2025-09-14T14:33:58.935991Z",
          "shell.execute_reply": "2025-09-14T14:33:58.935077Z",
          "shell.execute_reply.started": "2025-09-14T14:33:55.739002Z"
        },
        "id": "kN05Wln9KiBK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "vocab_size = len(mapping)\n",
        "embedding_size = 96\n",
        "hidden_size = 512\n",
        "\n",
        "#Some of the mapping are only for the encodeur so the decodeur can't produce them, we need to mask them from the loss\n",
        "mapping_inverse = {i: ch for ch, i in mapping.items()}\n",
        "masked_mapping = list(mapping_inverse.keys())[116:-1]\n",
        "\n",
        "mask = torch.zeros(vocab_size, dtype=torch.bool, device=device)\n",
        "mask[masked_mapping] = True\n",
        "\n",
        "enco = Encodeur_Atten(vocab_size, embedding_size, hidden_size, num_layers=2).to(device)\n",
        "deco = Decoder_Atten(vocab_size, embedding_size, hidden_size, mask,num_layers=2).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Decoder_Atten(\n",
              "  (embed): Embedding(223, 96)\n",
              "  (lstm): LSTM(608, 512, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (final): Linear(in_features=512, out_features=223, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ckpt = torch.load(\"..\\Models\\Seq2seq_att_model.pt\", map_location=\"cpu\")\n",
        "\n",
        "enco.load_state_dict(ckpt[\"encoder_state_dict\"])\n",
        "deco.load_state_dict(ckpt[\"decoder_state_dict\"])\n",
        "\n",
        "enco.eval()\n",
        "deco.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparation before generating "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to create the first context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<BEGINNING>', '<COUPLET>', '<REFRAIN>', '<COUPLET>', '<REFRAIN>', '<OUTRO>', '<END>']\n"
          ]
        }
      ],
      "source": [
        "struct = generate_a_song_structure(prob_transi.astype(float),states)\n",
        "\n",
        "struct = ['<BEGINNING>', '<COUPLET>', '<REFRAIN>', '<COUPLET>', '<REFRAIN>', '<END>']\n",
        "len_struct = [4, 3, 4, 3]\n",
        "\n",
        "encoded = torch.tensor([mapping[c] for c in struct[1]], dtype=torch.long).unsqueeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At first I need to generate the context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_result = []\n",
        "for i in range(len(struct[1:-1])) :\n",
        "\n",
        "    context_part = f\"<PART={struct[i+1][1:-1]}>\" \n",
        "    lines_tot = len_struct[i]\n",
        "    final_result.extend([\"\\n\",struct[i+1],\"\\n\\n\"])\n",
        "    \n",
        "    for j in range(1,lines_tot+1) :\n",
        "        #Context creation and encoding\n",
        "        context = []\n",
        "        context_encode = []\n",
        "    \n",
        "        #song's part\n",
        "        context.extend([context_part])\n",
        "\n",
        "        #lines\n",
        "        cont_lines = [f\"<lines={j}>\", f\"<total={lines_tot}>\"]\n",
        "        context.extend(cont_lines)\n",
        "\n",
        "        #previous lines\n",
        "        if j == 1 :\n",
        "            cont_previous = ['Previous :', \"<START>\", 'Previous :',  \"<START>\"]\n",
        "        else : #Add generated text back into the context \n",
        "            cont_previous[1] = result.split(\"<EOL>\")[0]\n",
        "            cont_previous[3] = result.split(\"<EOL>\")[1]\n",
        "        \n",
        "        context.extend(cont_previous)\n",
        "\n",
        "        #Context encoding\n",
        "        new_context = []         \n",
        "        for part in context : \n",
        "            if part in mapping :\n",
        "                new_context.extend([mapping[part]])\n",
        "            else : \n",
        "                for j in part :\n",
        "                    new_context.extend([mapping[j]])\n",
        "\n",
        "        length_cont = len(new_context)\n",
        "\n",
        "        #Whole generation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            encod_out, length_out, h, c = enco(torch.tensor([new_context]), torch.tensor([length_cont]))\n",
        "\n",
        "            arange = torch.arange(torch.tensor([new_context]).shape[1], device=length_out.device).unsqueeze(0)\n",
        "            mask_attn = (arange < length_out.unsqueeze(1)).to(device)\n",
        "\n",
        "            input_t = torch.tensor([mapping[\"START\"]])\n",
        "            outputs = [\"START\"]\n",
        "\n",
        "            while outputs[-1] != \"END\" :\n",
        "\n",
        "                embedded = deco.dropout(deco.embed(input_t))\n",
        "                query = h[-1]\n",
        "\n",
        "                scores = torch.bmm(encod_out, query.unsqueeze(2)).squeeze(2)\n",
        "                scores = scores.masked_fill(mask_attn == 0, float('-inf'))\n",
        "\n",
        "                weights = F.softmax(scores, dim=-1)\n",
        "                h_prime = torch.bmm(weights.unsqueeze(1), encod_out).squeeze(1)\n",
        "\n",
        "                lstm_in = torch.cat([embedded, h_prime], dim=-1).unsqueeze(1)\n",
        "                out, (h, c) = deco.lstm(lstm_in, (h, c))\n",
        "\n",
        "                logit = deco.final(out.squeeze(1))  # (B, vocab_size)\n",
        "                masked_logit = logit.masked_fill(deco.mask, float(\"-inf\"))\n",
        "\n",
        "                temperature = 0.5\n",
        "                top_k = 20\n",
        "                \n",
        "                probs = torch.softmax(masked_logit/temperature, dim=-1)\n",
        "                topk_probs, topk_idx = torch.topk(probs, top_k, dim=-1)\n",
        "\n",
        "                idx = torch.multinomial(topk_probs, 1)\n",
        "                next_token = topk_idx.gather(-1, idx)\n",
        "\n",
        "                outputs.append(int2char[next_token.item()])\n",
        "\n",
        "                input_t = next_token.squeeze(1)\n",
        "\n",
        "                result = \"\".join(outputs[1:-1])\n",
        "\n",
        "        for line in result.split(\"<EOL>\") :\n",
        "            if \"<\" in line :\n",
        "                continue\n",
        "            final_result.extend([line,\"\\n\"])\n",
        "\n",
        "final_result.extend([\"\\n\",\"<END>\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "<COUPLET>\n",
            "\n",
            "J'suis dans la soupe, j'ai fait l'fil de mon cœur\n",
            "Y'a pas d'rester calmer, en vrai j'suis pas d'jouer le soir d'espoir de l'argent du mal à sang\n",
            "Depuis le casse-coupe de mes potes et partir\n",
            "J'ai fait la politique, j'me sens changer dans les cartes d'eau en côté d'excitation\n",
            "J'ai vu des meufs qui m'ramènent pas d'foot avant qu'j'étais seul\n",
            "J'ai des frères, j'ai mis des extrêmes de manière sous l'issue\n",
            "Nique les fantômes comme deux ans d'faire des doigts\n",
            "Qu'est comme un peu d'bain de la rue, on s'en traite à ceux qu'ont des formes\n",
            "\n",
            "<REFRAIN>\n",
            "\n",
            "Son of a bitch\n",
            "Son of, son of a bitch\n",
            "Définition d'un OG\n",
            "Définition d'un OG\n",
            "Dojo F pour le mal-être, j'ai cette chance\n",
            "Mais j'ai b'soin d'mon lotissement\n",
            "\n",
            "<COUPLET>\n",
            "\n",
            "J'aimerais bien faire le corps de toute façon, j'incarne un seul comme la foi du plus d'entraire\n",
            "J'ai l'âme et l'argent de propre avec des marques\n",
            "J'ai pas de fermer la chatte, c'est pas d'chicha, la partie d'une vie en bataille\n",
            "J'me sens comme un riz et les sous-bizarres\n",
            "J'préfère être des meufs et puis un mec des couplets veulent du noir\n",
            "Entre le vent d'un anti-som dans le corps de pistessetiers\n",
            "Que le marque, donc j'viens d'un reuf du monde\n",
            "Si tu veux m'faire des potes comme un profond du chair et j'vais m'parler au commando\n",
            "\n",
            "<REFRAIN>\n",
            "\n",
            "J'veux pas rendre soit t'inquiète mais est ce qu'on va la niquer celle-là\n",
            "On va t'jeter de tout c'qu'il me reste\n",
            "Tu sais, c'est mon dernier mot petit chez nous\n",
            "Oh putain\n",
            "\n",
            "<END>\n"
          ]
        }
      ],
      "source": [
        "print(\"\".join(final_result))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 8228362,
          "sourceId": 13008689,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31089,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
