{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f62de5c",
   "metadata": {},
   "source": [
    "# This code will serve as a way to organize the corpus before training the Seq2seq model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017cf50f",
   "metadata": {},
   "source": [
    "#### Previous version : separation by parts (VERSE/INTRO/ETC...)\n",
    "#### New version : separation by parts / by 2 lines "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d5d6f",
   "metadata": {},
   "source": [
    "What this version will need for context of the Seq2seq :\n",
    "\n",
    "- The length of the parts\n",
    "\n",
    "- The previous two lines of txt, if no lines specific embedding\n",
    "\n",
    "- The parts name\n",
    "\n",
    "- At what stage appear our text : if appear at the beginning ==> 0/length_part = 0 / at the middle maybe 0.5 at the end 1\n",
    "\n",
    "if we are at the beginning and at the end, (less than two lines in a part), I will choose to set it to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ca8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f85ebb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991587"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files = os.listdir(\"../Corpus/Cleaning/\")\n",
    "\n",
    "new_corp = []\n",
    "for i in list_files :\n",
    "    if \"clean_corpus\" in i  :\n",
    "        with open(f\"../Corpus/Cleaning/{i}\", \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "            corpus = f.read()\n",
    "            new_corp.extend(corpus)\n",
    "corpus = \"\".join(new_corp)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e235e71",
   "metadata": {},
   "source": [
    "ok now the corpus will be modified to be able to be used in a Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ca7cf5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.replace(\"§\",\"<EOS>\")\n",
    "corpus = corpus.replace(\"\\n\",\"<EOL>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8845fb8",
   "metadata": {},
   "source": [
    "#### Pre-select the songs with parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e44f993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443 417\n"
     ]
    }
   ],
   "source": [
    "all_inside_parts = re.findall(r\"<BEGINNING><EOL>(.*?)<END>\", corpus, flags=re.DOTALL)\n",
    "\n",
    "new_inside = []\n",
    "for j in all_inside_parts :\n",
    "    if j[0] == \"<\" :\n",
    "        new_inside.append(j)\n",
    "\n",
    "print(len(all_inside_parts),len(new_inside))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc0321",
   "metadata": {},
   "source": [
    "#### Get all the parts indication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a2a590ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1444"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parts_indic = []\n",
    "for i in new_inside :\n",
    "    parts_indic = re.findall(r\"<(\\w+>)<EOL>.*?<EOL><EOS>\", i, flags=re.DOTALL)\n",
    "    for i in range(len(parts_indic)) :\n",
    "        parts_indic[i] = \"<PART=\"+parts_indic[i]\n",
    "\n",
    "    all_parts_indic.extend(parts_indic)\n",
    "    #For previous version use extend\n",
    "\n",
    "len(all_parts_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ee33fd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PART=REFRAIN>'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parts_indic[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0614166",
   "metadata": {},
   "source": [
    "#### Get all the inside part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fdf07f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inside_parts = []\n",
    "for i in new_inside :\n",
    "    all_inside = re.findall(r\"<\\w+><EOL>(.*?)<EOL><EOS>\", i, flags=re.DOTALL)\n",
    "    all_inside_parts.extend(all_inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f6c5a07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh<EOL>J'suis dans mon élément eh, j'suis dans mon élément<EOL>On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh<EOL>J'suis dans mon élément eh, j'suis dans mon élément\""
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inside_parts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3e042d",
   "metadata": {},
   "source": [
    "#### Next regroup the lines inside a part by group of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1e0897a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inside_parts_sep = []\n",
    "all_inside_parts_indic = []\n",
    "\n",
    "for part in all_inside_parts :\n",
    "    new = []\n",
    "    other_new = []\n",
    "\n",
    "    inside = part.split(\"<EOL>\")\n",
    "    for j in range(len(inside)) :\n",
    "        if j%2!=0 : #Only if odd number, indicate that we can have a tuple\n",
    "\n",
    "        #We can also use the same code to add the two previous lines to the context\n",
    "            if j==1 : #First two lines have no previous lines in the part\n",
    "                other_new.append([\"<START>\",\"<START>\"])\n",
    "            elif j>1 :\n",
    "                other_new.append(new[-1])\n",
    "            new.append([inside[j-1],inside[j]])\n",
    "\n",
    "        #Pb if the last j isn't odd then the last lines isn't added into it\n",
    "        elif (j == len(inside)-1) and (j%2==0) :\n",
    "            if j==0 : #Only one line so no previous line to append\n",
    "                other_new.append([\"<START>\",\"<START>\"])\n",
    "            else : \n",
    "                other_new.append(new[-1])\n",
    "            new.append([inside[j],'<NOTHING>'])\n",
    "\n",
    "    all_inside_parts_sep.append(new)\n",
    "    all_inside_parts_indic.append(other_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1554f50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_inside_parts_indic[1]),len(all_inside_parts_sep[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdbac76",
   "metadata": {},
   "source": [
    "#### Get the nb of group of lines per parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5c23ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_lines = []\n",
    "\n",
    "for j in all_inside_parts :\n",
    "    nb = j.count(\"<EOL>\")+1\n",
    "    if nb%2==0 :\n",
    "        adapt_nb = nb/2\n",
    "    else :\n",
    "        adapt_nb = (nb+1)/2\n",
    "    nb_lines.append(int(adapt_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96107035",
   "metadata": {},
   "source": [
    "#### Get the progression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2c07c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_inside_lines = []\n",
    "inside_lines = []\n",
    "\n",
    "for i in nb_lines:\n",
    "    inside_ = []\n",
    "    if i%2!= 0 :\n",
    "        for j in range(i) :\n",
    "            inside_.append(j+1)\n",
    "            if j not in mapping_inside_lines :\n",
    "                mapping_inside_lines.append(j+1)\n",
    "    else : \n",
    "        for j in range(i) :\n",
    "            inside_.append(j+1)\n",
    "            if j not in mapping_inside_lines :\n",
    "                 mapping_inside_lines.append(j+1)\n",
    "    inside_lines.append(inside_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be7f10",
   "metadata": {},
   "source": [
    "Now little check to see if everything works as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1fbdef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PART=REFRAIN>\n",
      "On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh<EOL>J'suis dans mon élément eh, j'suis dans mon élément<EOL>On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh<EOL>J'suis dans mon élément eh, j'suis dans mon élément\n",
      "1 2 \n",
      "Previous_lines : ['<START>', '<START>'] \n",
      "Actual lines : [\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh\", \"J'suis dans mon élément eh, j'suis dans mon élément\"]\n",
      "2 2 \n",
      "Previous_lines : [\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh\", \"J'suis dans mon élément eh, j'suis dans mon élément\"] \n",
      "Actual lines : [\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh\", \"J'suis dans mon élément eh, j'suis dans mon élément\"]\n"
     ]
    }
   ],
   "source": [
    "print(all_parts_indic[1])\n",
    "print(all_inside_parts[1])\n",
    "for j in range(len(all_inside_parts_sep[1])) :\n",
    "    print(inside_lines[1][j],nb_lines[1],\"\\nPrevious_lines :\",all_inside_parts_indic[1][j], \"\\nActual lines :\",all_inside_parts_sep[1][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1a8f8f",
   "metadata": {},
   "source": [
    "### Ok everything for the context is done, now I need to regroup them into a context variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "09e7338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PART=REFRAIN>\n",
      "On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh<EOL>J'suis dans mon élément eh, j'suis dans mon élément<EOL>On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh<EOL>J'suis dans mon élément eh, j'suis dans mon élément<EOL>On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh<EOL>J'suis dans mon élément eh, j'suis dans mon élément<EOL>On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh<EOL>J'suis dans mon élément eh, j'suis dans mon élément\n",
      "1 4 \n",
      "Previous_lines : ['<START>', '<START>'] \n",
      "Actual lines : [\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh\", \"J'suis dans mon élément eh, j'suis dans mon élément\"]\n",
      "2 4 \n",
      "Previous_lines : [\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh\", \"J'suis dans mon élément eh, j'suis dans mon élément\"] \n",
      "Actual lines : [\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh\", \"J'suis dans mon élément eh, j'suis dans mon élément\"]\n",
      "3 4 \n",
      "Previous_lines : [\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh\", \"J'suis dans mon élément eh, j'suis dans mon élément\"] \n",
      "Actual lines : [\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh\", \"J'suis dans mon élément eh, j'suis dans mon élément\"]\n",
      "4 4 \n",
      "Previous_lines : [\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh\", \"J'suis dans mon élément eh, j'suis dans mon élément\"] \n",
      "Actual lines : [\"On vit sous tension et c'est tout l'temps sombre et j'm'en fous dans l'fond, j'suis dans mon élément, eh\", \"J'suis dans mon élément eh, j'suis dans mon élément\"]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_parts_indic)): \n",
    "    print(all_parts_indic[i])\n",
    "    print(all_inside_parts[i])\n",
    "    for j in range(len(all_inside_parts_sep[i])) :\n",
    "        print(inside_lines[i][j],nb_lines[i],\"\\nPrevious_lines :\",all_inside_parts_indic[i][j], \"\\nActual lines :\",all_inside_parts_sep[i][j])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ae35d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = []\n",
    "context_two = []\n",
    "\n",
    "for i in range(len(all_parts_indic)): \n",
    "    for j in range(len(all_inside_parts_sep[i])) :\n",
    "#I need to separate the two because Previous will be a list of list inside a list and that will not be able to save to parquet easily\n",
    "        context.append([all_parts_indic[i],\"<lines=\"+str(inside_lines[i][j])+\">\",\"<total=\"+str(nb_lines[i])+\">\"])\n",
    "        context_two.append([\"Previous :\",all_inside_parts_indic[i][j][0],\"Previous :\",all_inside_parts_indic[i][j][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "137b9a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PART=COUPLET>',\n",
       " '<PART=INTRO>',\n",
       " '<PART=OUTRO>',\n",
       " '<PART=PONT>',\n",
       " '<PART=REFRAIN>'}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_parts_indic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75511ef0",
   "metadata": {},
   "source": [
    "#### Now that I have everything, I can prepare for the new vocab mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7bed3f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<lines=10>',\n",
       " '<lines=11>',\n",
       " '<lines=12>',\n",
       " '<lines=13>',\n",
       " '<lines=14>',\n",
       " '<lines=15>',\n",
       " '<lines=16>',\n",
       " '<lines=17>',\n",
       " '<lines=18>',\n",
       " '<lines=19>',\n",
       " '<lines=1>',\n",
       " '<lines=20>',\n",
       " '<lines=21>',\n",
       " '<lines=22>',\n",
       " '<lines=23>',\n",
       " '<lines=24>',\n",
       " '<lines=25>',\n",
       " '<lines=26>',\n",
       " '<lines=27>',\n",
       " '<lines=28>',\n",
       " '<lines=29>',\n",
       " '<lines=2>',\n",
       " '<lines=30>',\n",
       " '<lines=31>',\n",
       " '<lines=32>',\n",
       " '<lines=33>',\n",
       " '<lines=34>',\n",
       " '<lines=35>',\n",
       " '<lines=36>',\n",
       " '<lines=37>',\n",
       " '<lines=38>',\n",
       " '<lines=39>',\n",
       " '<lines=3>',\n",
       " '<lines=40>',\n",
       " '<lines=41>',\n",
       " '<lines=42>',\n",
       " '<lines=43>',\n",
       " '<lines=44>',\n",
       " '<lines=45>',\n",
       " '<lines=46>',\n",
       " '<lines=47>',\n",
       " '<lines=48>',\n",
       " '<lines=49>',\n",
       " '<lines=4>',\n",
       " '<lines=50>',\n",
       " '<lines=51>',\n",
       " '<lines=52>',\n",
       " '<lines=53>',\n",
       " '<lines=54>',\n",
       " '<lines=55>',\n",
       " '<lines=56>',\n",
       " '<lines=57>',\n",
       " '<lines=58>',\n",
       " '<lines=59>',\n",
       " '<lines=5>',\n",
       " '<lines=60>',\n",
       " '<lines=61>',\n",
       " '<lines=62>',\n",
       " '<lines=63>',\n",
       " '<lines=6>',\n",
       " '<lines=7>',\n",
       " '<lines=8>',\n",
       " '<lines=9>'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_inside_lines = []\n",
    "for i in inside_lines :\n",
    "    for j in i :\n",
    "        if j not in mapping_inside_lines: \n",
    "            mapping_inside_lines.append(\"<lines=\"+str(j)+\">\")\n",
    "set(mapping_inside_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a4d64680",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_nb_lines = []\n",
    "for i in set(nb_lines) :\n",
    "    mapping_nb_lines.append(\"<total=\"+str(i)+\">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "aec40fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PART=INTRO>',\n",
       " '<PART=OUTRO>',\n",
       " '<PART=PONT>',\n",
       " '<PART=REFRAIN>',\n",
       " '<PART=COUPLET>']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(all_parts_indic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ffe729",
   "metadata": {},
   "source": [
    "Creation of mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "370daeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vocab = []\n",
    "new_all_inside_parts = []\n",
    "for songs in all_inside_parts_sep :\n",
    "\n",
    "    new_parts = []\n",
    "    for parts in songs :\n",
    "        \n",
    "        new_two_lines = []\n",
    "        for two_lines in parts :\n",
    "            if len(new_two_lines) == 0 :\n",
    "                new_two_lines.extend(two_lines)\n",
    "                new_two_lines.append('<EOL>')\n",
    "            else : \n",
    "                new_two_lines.extend(two_lines)\n",
    "        full_vocab.extend(new_two_lines)\n",
    "\n",
    "        new_parts.append(new_two_lines)\n",
    "    new_all_inside_parts.append(new_parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "962cde2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PART=INTRO>',\n",
       " '<PART=OUTRO>',\n",
       " '<PART=PONT>',\n",
       " '<PART=REFRAIN>',\n",
       " '<PART=COUPLET>',\n",
       " '<total=3>',\n",
       " '<total=21>',\n",
       " '<total=41>',\n",
       " '<total=20>',\n",
       " '<total=22>',\n",
       " '<total=6>',\n",
       " '<total=63>',\n",
       " '<total=9>',\n",
       " '<total=27>',\n",
       " '<total=16>',\n",
       " '<total=23>',\n",
       " '<total=11>',\n",
       " '<total=2>',\n",
       " '<total=7>',\n",
       " '<total=17>',\n",
       " '<total=18>',\n",
       " '<total=28>',\n",
       " '<total=5>',\n",
       " '<total=19>',\n",
       " '<total=13>',\n",
       " '<total=36>',\n",
       " '<total=44>',\n",
       " '<total=29>',\n",
       " '<total=12>',\n",
       " '<total=25>',\n",
       " '<total=35>',\n",
       " '<total=39>',\n",
       " '<total=30>',\n",
       " '<total=8>',\n",
       " '<total=14>',\n",
       " '<total=1>',\n",
       " '<total=10>',\n",
       " '<total=24>',\n",
       " '<total=15>',\n",
       " '<total=4>',\n",
       " '<lines=19>',\n",
       " '<lines=43>',\n",
       " '<lines=61>',\n",
       " '<lines=16>',\n",
       " '<lines=54>',\n",
       " '<lines=55>',\n",
       " '<lines=37>',\n",
       " '<lines=23>',\n",
       " '<lines=5>',\n",
       " '<lines=22>',\n",
       " '<lines=47>',\n",
       " '<lines=60>',\n",
       " '<lines=26>',\n",
       " '<lines=18>',\n",
       " '<lines=14>',\n",
       " '<lines=40>',\n",
       " '<lines=4>',\n",
       " '<lines=50>',\n",
       " '<lines=21>',\n",
       " '<lines=56>',\n",
       " '<lines=30>',\n",
       " '<lines=44>',\n",
       " '<lines=49>',\n",
       " '<lines=51>',\n",
       " '<lines=15>',\n",
       " '<lines=35>',\n",
       " '<lines=62>',\n",
       " '<lines=17>',\n",
       " '<lines=39>',\n",
       " '<lines=42>',\n",
       " '<lines=34>',\n",
       " '<lines=31>',\n",
       " '<lines=38>',\n",
       " '<lines=28>',\n",
       " '<lines=45>',\n",
       " '<lines=48>',\n",
       " '<lines=53>',\n",
       " '<lines=24>',\n",
       " '<lines=3>',\n",
       " '<lines=10>',\n",
       " '<lines=6>',\n",
       " '<lines=7>',\n",
       " '<lines=11>',\n",
       " '<lines=58>',\n",
       " '<lines=25>',\n",
       " '<lines=52>',\n",
       " '<lines=20>',\n",
       " '<lines=33>',\n",
       " '<lines=8>',\n",
       " '<lines=46>',\n",
       " '<lines=2>',\n",
       " '<lines=41>',\n",
       " '<lines=29>',\n",
       " '<lines=32>',\n",
       " '<lines=1>',\n",
       " '<lines=63>',\n",
       " '<lines=57>',\n",
       " '<lines=27>',\n",
       " '<lines=59>',\n",
       " '<lines=9>',\n",
       " '<lines=13>',\n",
       " '<lines=12>',\n",
       " '<lines=36>']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special = list(set(all_parts_indic))+ list(set(mapping_nb_lines))+list(set(mapping_inside_lines))\n",
    "special"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276deb7",
   "metadata": {},
   "source": [
    "Two vocabs : One for the Encodeur and One for the Decodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7977f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_vocab = {ch: i for i, ch in enumerate([\"<PAD>\"]+list(set(full_vocab))+special+[\"<START>\"]+[\"Previous :\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "810a5fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_vocab = {ch: i for i, ch in enumerate([\"<PAD>\"]+list(set(full_vocab))+[\"START\",\"END\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e5156c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vocab = {ch: i for i, ch in enumerate([\"<PAD>\"]+sorted(list(set(full_vocab)))+special+[\"<START>\"]+[\"Previous :\"]+[\"START\"]+[\"END\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5a3f0",
   "metadata": {},
   "source": [
    "#### Now we need to first convert our datas to values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bce47602",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_input = list(itertools.chain.from_iterable(new_all_inside_parts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d017762",
   "metadata": {},
   "source": [
    "We need to add the first token indicating the start and the final token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6d2728da",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_flat = []\n",
    "\n",
    "for i in flat_input :\n",
    "    inter_ = [\"START\"]\n",
    "    inter_.extend(i)\n",
    "    inter_ +=[\"END\"]\n",
    "    final_flat.append(inter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5151f",
   "metadata": {},
   "source": [
    "## Pre-tokenize everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7f519b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_encode = [[global_vocab[i] for i in elem] for elem in context]\n",
    "final_encoded = [[global_vocab[i] for i in elem] for elem in final_flat]\n",
    "#context_two_encode = [[char2int[i] if (i) in (\"Previous :\",\"<START>\") else [char2int[j] for j in i]  for i in elem] for elem in context_two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1576df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_two_encode = []\n",
    "for i in (context_two) :\n",
    "    inter_contest_two = []\n",
    "    for j in i :\n",
    "        if \"Previous\" in j or \"<START>\" in j :\n",
    "            inter_contest_two.append(global_vocab[j])\n",
    "        else : \n",
    "            inter_contest_two.extend([global_vocab[char] for char in j])\n",
    "    context_two_encode.append(inter_contest_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "93b5a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_final = [a + b for a, b in zip(context_encode, context_two_encode)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678bfa4",
   "metadata": {},
   "source": [
    "## Modify the dataset to have a faster training and less compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "79f2ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_encoded_target = [elem[1:] for elem in final_encoded]\n",
    "final_encoded_input = [elem[:-1] for elem in final_encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb58e1",
   "metadata": {},
   "source": [
    "I can save directly into np.arrays to save a bit of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "811a35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.array([len(s) for s in context_final], dtype=np.int16)\n",
    "offsets = np.zeros(len(context_final), dtype=np.int32)\n",
    "offsets[1:] = np.cumsum(lengths)[:-1]\n",
    "context_np = np.array(list(itertools.chain.from_iterable(context_final)),dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b37d6fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Files/files_npy/context_np.npy\",context_np)\n",
    "np.save(\"Files/files_npy/context_length.npy\",lengths)\n",
    "np.save(\"Files/files_npy/context_offset.npy\",offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c0d7666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.array([len(s) for s in final_encoded_target], dtype=np.int16)\n",
    "offsets = np.zeros(len(final_encoded_target), dtype=np.int32)\n",
    "offsets[1:] = np.cumsum(lengths)[:-1]\n",
    "final_np = np.array(list(itertools.chain.from_iterable(final_encoded_target)),dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e885f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Files/files_npy/Y_np.npy\",final_np)\n",
    "np.save(\"Files/files_npy/Y_length.npy\",lengths)\n",
    "np.save(\"Files/files_npy/Y_offset.npy\",offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d9a2e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = np.array([len(s) for s in final_encoded_input], dtype=np.int16)\n",
    "offsets = np.zeros(len(final_encoded_input), dtype=np.int32)\n",
    "offsets[1:] = np.cumsum(lengths)[:-1]\n",
    "final_np = np.array(list(itertools.chain.from_iterable(final_encoded_input)),dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0f5de958",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Files/files_npy/X_np.npy\",final_np)\n",
    "np.save(\"Files/files_npy/X_length.npy\",lengths)\n",
    "np.save(\"Files/files_npy/X_offset.npy\",offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba3c56",
   "metadata": {},
   "source": [
    "# Create the dataset that will contain everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a27bc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Files/Encoding_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(global_vocab, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
