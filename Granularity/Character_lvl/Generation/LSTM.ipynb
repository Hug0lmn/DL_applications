{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:20:43.767688Z",
     "iopub.status.busy": "2025-08-26T13:20:43.767446Z",
     "iopub.status.idle": "2025-08-26T13:20:48.176921Z",
     "shell.execute_reply": "2025-08-26T13:20:48.176138Z",
     "shell.execute_reply.started": "2025-08-26T13:20:43.767664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlm/Documents/Stanford Course/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..')))\n",
    "from Functions_generation import generate_a_song_structure, sample_with_temp_topk, Char_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:20:48.179209Z",
     "iopub.status.busy": "2025-08-26T13:20:48.178868Z",
     "iopub.status.idle": "2025-08-26T13:20:48.204248Z",
     "shell.execute_reply": "2025-08-26T13:20:48.203458Z",
     "shell.execute_reply.started": "2025-08-26T13:20:48.179190Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"../../../Corpus/Encoding_RNN_LSTM/Char_level/encoding_map.pkl\", \"rb\") as f:\n",
    "    mapping = pickle.load(f)\n",
    "\n",
    "int2char = {i: ch for ch, i in mapping.items()}\n",
    "nb_char = len(int2char)\n",
    "mapping[\"PAD\"] = len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_csv(\"../../../Markov/transition_matrix.csv\")\n",
    "\n",
    "states = np.array(matrix.iloc[6])\n",
    "prob_transi = np.array(matrix.iloc[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(mapping)\n",
    "\n",
    "model = Char_LSTM(vocab_size)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"../Models/LSTM_model.pt\", map_location=\"cpu\")\n",
    "\n",
    "new_state_dict = {}\n",
    "for key, value in ckpt[\"model_state_dict\"].items():\n",
    "    new_key = key.replace(\"_orig_mod.\", \"\")           \n",
    "    new_state_dict[new_key] = value\n",
    "\n",
    "ckpt[\"model_state_dict\"] = new_state_dict\n",
    "\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will give the same structure for RNN and LSTM to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BEGINNING>', '<INTRO>', '<COUPLET>', '<END>']\n"
     ]
    }
   ],
   "source": [
    "struct = generate_a_song_structure(prob_transi.astype(float),states)\n",
    "\n",
    "#struct = ['<BEGINNING>', '<COUPLET>', '<REFRAIN>', '<COUPLET>', '<REFRAIN>', '<END>']\n",
    "struct = ['α', 'γ', 'ε', 'γ', 'ε', 'θ']\n",
    "\n",
    "encoded = torch.tensor([mapping[c] for c in struct[1]], dtype=torch.long).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forbidden to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['α', 'β', 'γ', 'ε', 'ζ', 'η', 'θ', '€']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forbidden_generation = [i for i in range(64,72)]\n",
    "[int2char[i] for i in forbidden_generation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decod_structure = {\"β\" : \"<INTRO>\",\n",
    "                   \"γ\" : \"<COUPLET>\",\n",
    "                   \"ε\" : \"<REFRAIN>\",\n",
    "                   \"ζ\" : \"<PONT>\",\n",
    "                   \"η\" : \"<OUTRO>\",\n",
    "                   \"θ\" : \"<END>\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<COUPLET>\n",
      "\n",
      "voila pourquoi, cette chance sa batte, on l'mérite\n",
      "les rimes sont pas très calmes que tu souvenirs donc mon esprit s'entume\n",
      "le smic c'est pour les souvenirs, allez-y-raz pommédias\n",
      "j'te laisse moins d'bellines\n",
      "santé et au désordre, j'veux pas de touches\n",
      "ils diront qu'ils diraient qu'ils font des belles côtes\n",
      "leur dealer est palame, j'pense à tous chimir de netly\n",
      "tu veux qu'j'parle avec un mec avec l'encre et j'suis admirant\n",
      "pour toi, c'est die pute devant la mitraillette, tu pas as d'l'amour de standing\n",
      "j'apprends le miroir comme ça c'est devenu sépare\n",
      "face à double, faut s'mettre, ils connaissent pas les magnes\n",
      "j'suis pas du genre à l'overdav\n",
      "bâtir des bas longs, les fuls de com, alors, ouais, me surprouvertez ça\n",
      "et ça médite pas qu'on connait l'éciler, j'm'en branle devant ton daron comme armoty\n",
      "beaucoup de gestes, les moins veulent vous sombrer\n",
      "moi, man\n",
      "\n",
      "<REFRAIN>\n",
      "\n",
      "tous ves-qui les décès, j'étais pas encore dans le bien\n",
      "et j'suis seul à ma tête c'est dans l'four\n",
      "même les casseurs, des grosses montants\n",
      "j'suis pas parce banc c'est tous comis oùly, des tins-pi\n",
      "les strass, toutes ces meubles qui sont prêts de parler\n",
      "je respecte pour l'décor, j'fais pas vos queues qui demandent comme la lecture, le next, noger l'endar\n",
      "ils se doit cacher des vibroueaux, et en tout pour faire tout l'temps qui traîne dans le nez si t'as fais des taff de malheub's\n",
      "prendre chaque frangin si j'pense à france\n",
      "partout same shit, rentrer en retardés c'est le platone\n",
      "t'en vis ou t'es pas d'air et dans ton réseau serait faipn du choisi\n",
      "parcourais ton chick entre les potos, l'bonheur est pas tout ces hasch\n",
      "t'as lui court\n",
      "j'me mets un dos dans la tête ou des grammes\n",
      "on s'passera vite dans le vague mal, j'espèce au foi\n",
      "en plus tard on est têtés comme oufa\n",
      "si bordé je dois être l'seum dans l'flou, là où ça fait: faut qu'on est seul\n",
      "j'pense aux questions, l'orage et le tablack\n",
      "face à tous les sous cette plange est bleu\n",
      "j'comprends pas moi et si je dois aller me dire de quoi tu pises?\n",
      "j'veux pas qu'ça va pour toi\n",
      "quand je traverse le justice à l'espoir et triste\n",
      "pour savoir ado c'est mon poste et mes principes flux, on les entendra pieds\n",
      "pas de ballon est taré, tu t'renfocces pas d'vacances\n",
      "toute la boîte\n",
      "on m'dit chantez d'voir ma pune, c'est des biftons plus\n",
      "et puis je m'écarte, il suffique de l'avance dans la sélicomand\n",
      "pour passer l'avoir, mon poto, fais pas l'sable saoul\n",
      "le rou c'est tois on me dit que j'y crois, faut qu'je retourne dans le vull bon travaud\n",
      "j'vis les sirènes, la haine est une autre braque\n",
      "bah ouais, j'ai promis à l'hôpital de vrait\n",
      "la voisine dése, désossé\n",
      "j'ai pas tout l'temps de passer, les yeux d'les grandes, j'te fais des sales titres\n",
      "créé mon an, j suis sur la tess', j'vis dans l'dés', j'suis pas fiké qu'a va sortir de l'homme?\n",
      "j'change des tours, ça fait des comments qu'on pense comme une coupe d'action\n",
      "jack jack, j'suis malade comme un pégan\n",
      "du feu à fini ou le ksy\n",
      "c'est chaud tout c'qu'il y a plus d'temps que j'étouffe et j'suis en action d'un p'tit million\n",
      "que j'ai dispar quatre-quatre ans chauds, on doit traîner dans mon chiffre\n",
      "tu peux te resserrer de la main avec les couns buzzels\n",
      "elle m'dit s'c'est un vrai tourner que des consesions\n",
      "la vie s'approche de la crimine pour les cents clus\n",
      "dans la mort à c'que j'ai fait de nike acord\n",
      "merci à nous, on est partis de nieux\n",
      "et si on tape le big au canal\n",
      "françois pignon, heureusement, c'est là\n",
      "\n",
      "<COUPLET>\n",
      "bdis, plus face le plu, j'ai reconfondu l'bluerarot du film-en\n",
      "j'suis un p'tit cul, c'est pluv'qu'un manalisé\n",
      "reste au bled nul, je le sens, j'avance\n",
      "j'ai rendu ma statut et si j'pleure mon futur mois j'raconte\n",
      "\n",
      "<REFRAIN>\n",
      "\n",
      "et j'passe pas mes junes comme brasées\n",
      "le prix de l'espoir c'est dead\n",
      "plus content mais qu'est-ce qu'on fait qu'on pourrait l'appeler l'édus\n",
      "j'ai grandi dans l'abrique, le voisin sera bien\n",
      "on s'connait pas pour les mauvais moments, piscines qu'il soit en chagrique\n",
      "comme ma bande, mon joint et ma pilliérurègne\n",
      "j'déteste l'ordre maintenant on est partis de mes amis\n",
      "toucher dans le coup, comment on pleus la famille pour souffrir pur du bar\n",
      "j'suis fier de moi\n",
      "j'pense au moontaga smillan\n",
      "le rap est ce demuieu, on n'a pas d'échecs et maader saint si t'as appris les découvertes\n",
      "on s'débrouille tauchement vip\n",
      "je me retourne je donne les morts de ta peau\n",
      "l'amour il m'a oublié, si le coup d'putain ça sert à rien d'les avant-glaco\n",
      "des mots coupurs c'est pas d'la nuit, tu s'ras frotté à vos regards pletins\n",
      "appelle ça puète flou marche en peau d'beuh\n",
      "mais, j'crois que y'a d'la vie de plus en plus de maricale\n",
      "même si ça inout est big ratimal\n",
      "\n",
      " <END>\n"
     ]
    }
   ],
   "source": [
    "context_gen = \"voila pourquoi, \"\n",
    "context_encode = [mapping[i] for i in context_gen]\n",
    "context_size = len(context_encode)\n",
    "\n",
    "hid = model.init_hidden(batch_size=1)\n",
    "\n",
    "for i in range(len(struct) - 2):\n",
    "\n",
    "    print()\n",
    "    print(decod_structure[struct[i+1]])\n",
    "\n",
    "    if i == 0 : \n",
    "        context_encode.insert(0,mapping[struct[i+1]])\n",
    "        context_encode.insert(1,mapping[\"\\n\"])\n",
    "        encoded = torch.tensor(context_encode, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "        print(\"\".join([int2char[i] for i in context_encode[1:]]), end=\"\")\n",
    "\n",
    "        out, hid = model(encoded, hid)\n",
    "        next_input = encoded[:, -1].unsqueeze(0)  # shape (1, 1)\n",
    "\n",
    "    else : \n",
    "        #next_input = torch.tensor(mapping[struct[i+1]],dtype=torch.long).unsqueeze(0)\n",
    "        next_input = torch.tensor(mapping[struct[i+1]],dtype=torch.long).view(1,1)\n",
    "\n",
    "    last_input = 0\n",
    "    first_input = True\n",
    "\n",
    "    while last_input != 12:\n",
    "        with torch.no_grad():\n",
    "            out, hid = model(next_input, hid)   # out shape: (1, 1, vocab_size)\n",
    "\n",
    "            out[0, -1][forbidden_generation] = float(\"-inf\")\n",
    "\n",
    "        # 4. On échantillonne un token\n",
    "            next_token = sample_with_temp_topk(out[0, -1], temperature=0.9, top_k=15)\n",
    "            last_input = next_token.item()\n",
    "\n",
    "        # 5. Conditions d’impression\n",
    "            if first_input and last_input == 12:  # Si début et le modèle sort directement <END>\n",
    "                last_input = 0\n",
    "                continue\n",
    "\n",
    "            elif first_input and last_input == 0:  # Si début et sortie = \\n\n",
    "                first_input = False\n",
    "                forbidden_generation.extend([0])\n",
    "                print(int2char[next_token.item()], end=\"\")\n",
    "\n",
    "            elif next_token.item() != 12:\n",
    "                first_input = False\n",
    "                print(int2char[next_token.item()], end=\"\")\n",
    "\n",
    "                if 0 in forbidden_generation:\n",
    "                    forbidden_generation.pop(-1)\n",
    "\n",
    "        # 6. Préparer la prochaine entrée\n",
    "            next_input = next_token.view(1, 1)\n",
    "\n",
    "print(\"\\n\", decod_structure[struct[-1]])\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8138327,
     "sourceId": 12873076,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
