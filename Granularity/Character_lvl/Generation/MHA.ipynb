{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:20:43.767688Z",
     "iopub.status.busy": "2025-08-26T13:20:43.767446Z",
     "iopub.status.idle": "2025-08-26T13:20:48.176921Z",
     "shell.execute_reply": "2025-08-26T13:20:48.176138Z",
     "shell.execute_reply.started": "2025-08-26T13:20:43.767664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hlm/Documents/Stanford Course/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..')))\n",
    "from Functions_generation import generate_a_song_structure, sample_with_temp_topk, DecoderOnlyTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T13:20:48.179209Z",
     "iopub.status.busy": "2025-08-26T13:20:48.178868Z",
     "iopub.status.idle": "2025-08-26T13:20:48.204248Z",
     "shell.execute_reply": "2025-08-26T13:20:48.203458Z",
     "shell.execute_reply.started": "2025-08-26T13:20:48.179190Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"../../../Corpus/Encoding_RNN_LSTM/Char_level/encoding_map.pkl\", \"rb\") as f:\n",
    "    mapping = pickle.load(f)\n",
    "\n",
    "int2char = {i: ch for ch, i in mapping.items()}\n",
    "nb_char = len(int2char)\n",
    "mapping[\"PAD\"] = len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_csv(\"../../../Markov/transition_matrix.csv\")\n",
    "\n",
    "states = np.array(matrix.iloc[6])\n",
    "prob_transi = np.array(matrix.iloc[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(mapping)\n",
    "\n",
    "model = DecoderOnlyTransformer(vocab_size)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"../Models/MHA_model.pt\", map_location=\"cpu\")\n",
    "\n",
    "new_state_dict = {}\n",
    "for key, value in ckpt[\"model_state_dict\"].items():\n",
    "    new_key = key.replace(\"_orig_mod.\", \"\")           \n",
    "    new_state_dict[new_key] = value\n",
    "\n",
    "ckpt[\"model_state_dict\"] = new_state_dict\n",
    "\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will give the same structure for RNN and LSTM to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BEGINNING>', '<INTRO>', '<COUPLET>', '<REFRAIN>', '<COUPLET>', '<COUPLET>', '<OUTRO>', '<END>']\n"
     ]
    }
   ],
   "source": [
    "struct = generate_a_song_structure(prob_transi.astype(float),states)\n",
    "\n",
    "#struct = ['<BEGINNING>', '<COUPLET>', '<REFRAIN>', '<COUPLET>', '<REFRAIN>', '<END>']\n",
    "struct = ['α', 'γ', 'ε', 'γ', 'ε', 'θ']\n",
    "\n",
    "encoded = torch.tensor([mapping[c] for c in struct[1]], dtype=torch.long).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forbidden to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['α', 'β', 'γ', 'ε', 'ζ', 'η', 'θ', '€']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forbidden_generation = [i for i in range(64,72)]\n",
    "[int2char[i] for i in forbidden_generation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decod_structure = {\"β\" : \"<INTRO>\",\n",
    "                   \"γ\" : \"<COUPLET>\",\n",
    "                   \"ε\" : \"<REFRAIN>\",\n",
    "                   \"ζ\" : \"<PONT>\",\n",
    "                   \"η\" : \"<OUTRO>\",\n",
    "                   \"θ\" : \"<END>\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<COUPLET>\n",
      "\n",
      "voila pourquoi, pon j'e\n",
      "eres pa ma fai j'ais t couris s las lai de de ceras e est's mmes pais me les lles le les dane lais le le de t mete plat pounden, l ce meretac'an le paran l'a maisur les\n",
      "j'le d'e le\n",
      "con s mes d t le pas c'es m'pe la t j'e lle e le lant me l\n",
      "launte\n",
      "les d's darese pan j'e mes c'es me dis esare le painte j'en je\n",
      "j'ai t cont s de le ches cre d le j's c d'es prairsust s qus, me t couai less ditons tres pr de\n",
      "tenntour, stitan les le pontra pa le pame es te moui, mpa d'e tre le de\n",
      "landis s mommoroue di pre pe lis ce que j'a mis s dis ce pas\n",
      "luire dous le es des es de ma lest e les pres couren pa d'aiese lererr s\n",
      "cac'e pacontenon man me d'one pa des pons de c'e j'ais de s pen, fis s, con le cre d's s t l ment pail'ais daistou de de pon d't d'e ce\n",
      "trouime pavon ce\n",
      "ou'es c'an s d'c'as trailess lanne aienn s cos e t l'ais j's t de lu'ois me s deme l'e dais de lande m'ame su dr te dis ptre des lais, t l'at s j'a ten e ve, je ais pes d's teue e, les pes lainen t tre c'rou's con paiesouin l'r j's c'its j'anaies da de canent las des\n",
      "llles menton t pois t de d'ent au'e, quren dis j'con de des pa poulennt es men des mesan ples me, le las t lales me cen par de s toirain le me\n",
      "s pailes coua se durit en c ce den eu dor de pon, pos s te doure pantere pl'a de le d'oun s muren d's dese s j'ate cles m's s meu de dantois pa lou'me der s ple qu'a d'es di le\n",
      "coun d'at cls ditas les me danoue de l'is toures de ll'ple lu s cont pares t dene be pame das j't j'an post s ton t pent t pon le s le pot pair d'a pon le s le le pous s d'les ques pon e c'estise, s plans\n",
      "j'ame me t pa s met qute, mes mant d's des c'pauri conen count pounsse cen lé, den e mes s, e s puness par venn l pe me t a j's les pe, peres ples doun pr la va t pou s manne pe ceute\n",
      "j'vas ces de s quliles de\n",
      "je le pont poue\n",
      "j'atrs s dait de de pas s ce t pai chais por s de t s poues de las maprer mes t j'ent mes s pis tentur pa pres en le ple t d's pe deu m'an d'are j'llanns mon di, lunenn ve me e conte l'touisais pan las des déte de cis me fle le de cis me qu dan s e le de j'a trite des mes pons con d'vas'tilaus de dules ce pave j'ares j'eres couis ces les fis cuidere\n",
      "t\n",
      "te qur s cun stemerilen d'es d'a s es e c'ar\n",
      "lles panten le mavan la j'etr dend'esone s dain des j'pas mouras me d'me, les s j'é mount j'oor l dis da don are me mane, s le paplait pe donen pa te llan s le j'a l'e, pat te\n",
      "e pa de t s pais peuins lenomaidendentemas j'ere le ches da te, d'aurit les j'e es s prd'a lle lais lain c's s me d tran d loure t t lai lan fane ces quran d'etomoni lu e la t'an le le e l'anan m'aires d'as lairouil'amareu ma fes entes, ce de le de pre dess mes daita leu cout mmuirisauis las de m'e duimen t de paire, mant t jan t e t d est t s des d'as lete le st d'en d's le l'es mpl's e mes, me j'fais, pant me les le loire j'ais s, les s peuimous pasur cl'ass ce d'tr pontier s le d'ous des j'anent le d'as l'cent j'mon qus tindenden le, pante t fature, coures d'inen t pait es de j'eu cous met s\n",
      "t d'es de a dis de le pai cis e cont dare mmpas d'e pe le dant lait de pa les c'an ces s les de, qu pare s le, le l'a de t pa s j'our c'ais s t'ant tre cons les ponte celet pu'an muroune lese d'aie d'trete me\n",
      "enetie len j'e de lau tetes dis den ls les d'es des tes painnti det e les, s qun c'e dire ci mou lai e pan les d caie pe, s pllere cou'airen lender de me d's d'pai pan pou'as de l'larene d'one des chante c't quis comont t chens de d d'paitis dint j'as cand'ane ma caitaranoranener leti de, mu mes poutue paie cai ce, j'air che plais ain t mintie de me j'leuere condon las tenches d'des de pouess counte dueren plliseura de ce ss ma c'ra t tete paita fan s\n",
      "cores qust j's j'ailes les de j'ant leu'ai dere t de t e stanite d'ant s des l's de j'aur\n",
      "our che\n",
      "le s les le pensaie lerde d'es le, me, cois lairavas ssus pre pes j'ans d'anenturere de fondes s j'es j'ait'alent me des ques taisene\n",
      "j'e pa tis me c'erou dene s pan me lle s le\n",
      "j'aurontre dan s ste de durer cout d'ont s ce pais, pa l'ai laris le bon s paras entit des, me d'es c'es t s es pas d'ar tré l'e ais leus proc'ais e\n",
      "dens de mar tou les\n",
      "j'ene d'a dais paies pr d'arise l'mise\n",
      "e an\n",
      "j't c'ren ce ss da ple pau l'a le desouist lais ces me d'er de s de te de len c'ain les pon de de lou parais c'e le s j'e t'me d'acor metirend le t e pr j'erans l's les de t quress e de\n",
      "t ps s coue de e dans ton te lenturr d'e c'ant t pon de durais sopais lentrames lons paie t chais de m'ant me j'est pan cou'a t e, c'a les lle paile mes pa qurala me, s l'é prrirét leri la j'e lente s e les ponst lais pes d'tan dairme pou pavres le mes de pan qure late poue de pandin j'itesten tras, des vess pais les me d'arene cit con j's, le me s m'ente de tene\n",
      "\n",
      "<REFRAIN>\n",
      "\n",
      "mon jes lais j'endarend'e cararentuis ss laint lais le, pour paiset j'a ca t d'ata le j'en t rsu d'ai t les on ce sell'a me memes llales lare le, pe pes s caisen purones mèt pone quirou te pant ton morene d'a me s pont, qux le te mons des e pl'ai\n",
      "\n",
      "<COUPLET>\n",
      "\n",
      "j'ais t eisis praus detr quis ce t tas mai dis me les dimese le l'e me ent pre drs fousure re fet mes fala s ds d'a li le lu t pouil'la de, d'e des le pamas ss pourais t trane des doui, j'alaitont'anain ds pla décome denne qui ls te mmar tons\n",
      "ler tes an caiss mmen desan t pa d'e des la dous, j'ari dant me e\n",
      "j'aite\n",
      "\n",
      "<REFRAIN>\n",
      " plourimere\n",
      "j'a derd'e le s l ppos e, cone cenness, cos t lai dos tant meues m'es pais t pe dou ce c'loues te leure de mes tau'mam'ie\n",
      "\n",
      " <END>\n"
     ]
    }
   ],
   "source": [
    "context_gen = \"voila pourquoi, \"\n",
    "context_encode = [mapping[i] for i in context_gen]\n",
    "context_size = len(context_encode)\n",
    "\n",
    "for i in range(len(struct) - 2):\n",
    "\n",
    "    print()\n",
    "    print(decod_structure[struct[i+1]])\n",
    "\n",
    "    if i == 0 : \n",
    "        context_encode.insert(0,mapping[struct[i+1]])\n",
    "        context_encode.insert(1,mapping[\"\\n\"])\n",
    "        encoded = torch.tensor(context_encode, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "        print(\"\".join([int2char[i] for i in context_encode[1:]]), end=\"\")\n",
    "\n",
    "        out = model(encoded)\n",
    "        next_input = encoded[:, -1].unsqueeze(0)  # shape (1, 1)\n",
    "\n",
    "    else : \n",
    "        next_input = torch.tensor(mapping[struct[i+1]],dtype=torch.long).view(1,1)\n",
    "\n",
    "    last_input = 0\n",
    "    first_input = True\n",
    "\n",
    "    while last_input != 12:\n",
    "        with torch.no_grad():\n",
    "            out = model(next_input)   # out shape: (1, 1, vocab_size)\n",
    "\n",
    "            out[0, -1][forbidden_generation] = float(\"-inf\")\n",
    "\n",
    "        # 4. On échantillonne un token\n",
    "            next_token = sample_with_temp_topk(out[0, -1], temperature=0.6, top_k=10)\n",
    "            last_input = next_token.item()\n",
    "\n",
    "        # 5. Conditions d’impression\n",
    "            if first_input and last_input == 12:  # Si début et le modèle sort directement <END>\n",
    "                last_input = 0\n",
    "                continue\n",
    "\n",
    "            elif first_input and last_input == 0:  # Si début et sortie = \\n\n",
    "                first_input = False\n",
    "                forbidden_generation.extend([0])\n",
    "                print(int2char[next_token.item()], end=\"\")\n",
    "\n",
    "            elif next_token.item() != 12:\n",
    "                first_input = False\n",
    "                print(int2char[next_token.item()], end=\"\")\n",
    "\n",
    "                if 0 in forbidden_generation:\n",
    "                    forbidden_generation.pop(-1)\n",
    "\n",
    "        # 6. Préparer la prochaine entrée\n",
    "            next_input = next_token.view(1, 1)\n",
    "\n",
    "print(\"\\n\", decod_structure[struct[-1]])\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8138327,
     "sourceId": 12873076,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
