{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd1881c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..')))\n",
    "from Functions_generation import generate_a_song_structure, sample_with_temp_topk, Char_RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2d8970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../../Corpus/Encoding_RNN_LSTM/Char_level/encoding_map.pkl\", \"rb\") as f:\n",
    "    mapping = pickle.load(f)\n",
    "\n",
    "mapping[\"PAD\"] = len(mapping)\n",
    "int2char = {i: ch for ch, i in mapping.items()}\n",
    "nb_char = len(int2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac870aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_csv(\"../../../Markov/transition_matrix.csv\")\n",
    "\n",
    "states = np.array(matrix.iloc[6])\n",
    "prob_transi = np.array(matrix.iloc[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f7fac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(int2char)\n",
    "model = Char_RNN(vocab_size, num_layers=3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03b2eb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"../Models/RNN_model.pt\", map_location=\"cpu\")\n",
    "\n",
    "new_state_dict = {}\n",
    "for key, value in ckpt[\"model_state_dict\"].items():\n",
    "    new_key = key.replace(\"_orig_mod.\", \"\")           \n",
    "    new_state_dict[new_key] = value\n",
    "\n",
    "ckpt[\"model_state_dict\"] = new_state_dict\n",
    "\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f93902e",
   "metadata": {},
   "source": [
    "I will give the same structure for RNN and LSTM to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "049b0ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<BEGINNING>', '<INTRO>', '<COUPLET>', '<OUTRO>', '<END>']\n"
     ]
    }
   ],
   "source": [
    "struct = generate_a_song_structure(prob_transi.astype(float),states)\n",
    "\n",
    "#struct = ['<BEGINNING>', '<COUPLET>', '<REFRAIN>', '<COUPLET>', '<REFRAIN>', '<END>']\n",
    "struct = ['α', 'γ', 'ε', 'γ', 'ε', 'θ']\n",
    "\n",
    "encoded = torch.tensor([mapping[c] for c in struct[1]], dtype=torch.long).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54be15",
   "metadata": {},
   "source": [
    "Forbidden to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f182654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['α', 'β', 'γ', 'ε', 'ζ', 'η', 'θ', '€']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forbidden_generation = [i for i in range(64,72)]\n",
    "[int2char[i] for i in forbidden_generation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf163652",
   "metadata": {},
   "outputs": [],
   "source": [
    "decod_structure = {\"β\" : \"<INTRO>\",\n",
    "                   \"γ\" : \"<COUPLET>\",\n",
    "                   \"ε\" : \"<REFRAIN>\",\n",
    "                   \"ζ\" : \"<PONT>\",\n",
    "                   \"η\" : \"<OUTRO>\",\n",
    "                   \"θ\" : \"<END>\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2333b81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<COUPLET>\n",
      "\n",
      "voila pourquoi, ils se promettre\n",
      "ça découpe c'est d'la musique ouais j'suis partout comme ça\n",
      "\n",
      "<REFRAIN>\n",
      "mon ombre\n",
      "sur la banquette, j'ai vu la même maison, on parle d'accord dans la secte\n",
      "un jour on s'en fout, ton rappeur s'embrouille, c'est mon seum on en ressente l'instru et ma vision cherche cette spectacle\n",
      "comme si c'était la place du début d'la guerre aux blagues de toi\n",
      "on baise très concentrée et j'vis ma force entièrement de la météan, le cash la course en ais-hop, faut qu'j'me dis pas vraiment des douze ans\n",
      "j'suis dans le fond\n",
      "pendant qu'j'me réveille, on fait pire\n",
      "prends une mots, j'vois trop d'faux, j'suis grave sur nos chances de mon terminable\n",
      "putain, tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois c'que j'veux dire\n",
      "tu vois  sku sku j'veux dire?\n",
      "ok, slide, slide\n",
      "ok, tu t'es baiser comme le mouvon\n",
      "j'veux une bonne voix de mon pote, si on m'a dit qu'j'suis l'temps pour rentrer dans le piège si t'es un film d'un homme en moi\n",
      "j'ai remplis la nuit\n",
      "j'mettrai pas mes cartes sont faibles\n",
      "c'est la casse\n",
      "dans mon seul à donner, rendez-vous à voir dans l'crâne pour qu'j'sois dar, j'vois des textes et des larmes qui pourraient haut comme album moi, aujourd'hui, c'est des airs frangins\n",
      "j'pense qu'à faire des couilles de s'envoler comme les anciens feuilles, les mères des pensées sont pas fini de plus rien d'spécial\n",
      "besoin d'me conseiller des meufs qui l'apprécient pas pour faire des coupeurs du microphone, mise avec ma bite n'prend les garcelles\n",
      "pour se faire des billets sourires\n",
      "mais j'suis pas là qui nous a violenté\n",
      "j'ai jamais fais un monde de l'attaque, là, j'ai l'temps d'm'appeler mais j'ai mes potes et les plans sous la terre se croie tout le ballon, mes espoirs sont dans l'dos sous tes paupières me dit qu'on posent les traces dans les cieux\n",
      "je sais même pas aussi, j'ai trop d'banque et des petits au studio et si j'rentre, j'ai perdu un corps\n",
      "et toutes les mauvais discours, j'ai peur du soleil, c'est un cerveau qui crache nul à pleurer, j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku sku sku\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire?\n",
      "ok, slide, slide\n",
      "ok, tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois c'que j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois c'que j'veux dire?\n",
      "ok, slide, slide\n",
      "ok, tu vois c'que j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois  sku sku j'veux dire\n",
      "tu vois c'que j'veux dire?\n",
      "nana\n",
      "la vie a fait charleroi n'est pas détruire la frappe tellement sublime\n",
      "je suis trop collée de mon innocence hey roi sur ma soirée et la vie qu'j'ai beau pas souvent quand j'réveille en boucle je ressens rien\n",
      "laisser mes rêves\n",
      "quand tu peux t'faire plaisir si j'ai la chance?\n",
      "j'ai oublié mon top\n",
      "en combatice\n",
      "\n",
      "<COUPLET>\n",
      "menari\n",
      "si tu m'croises le micro transpire, la paix est déjà le plus la répartition d'la tasse et avant ça\n",
      "viens jouer au soss, je n'ai la course et un point d'amour, j'cours après l'immange affronter les yeux devant l'asile\n",
      "le prochain même si j'ai sous cinq artistes sur le coffre, ils disent qu'j'suis avec mes affaires en cancer\n",
      "dans la rue et l'fila ou la chance que j'ai fait des gars te disent, j'suis dans le pied, le rap, on s'allume car ils s'en sortir, mais je sais qu't'es chez moi qui prend pas l'choix\n",
      "laisse-moi faire mon hit\n",
      "guette, j'vois tout l'monde se fait?\n",
      "j'ai pas sur moi\n",
      "je l'épuise en laisse\n",
      "je suis vide\n",
      "j'ai l'sang comme la banquière\n",
      "on s'met des coups d'problèmes\n",
      "les dièses persues dans l'studio ou un monde ride ensemble, j'ai pas peur de l'envers\n",
      "cerveau cassé car je peux pas l'rapper sur toi c'est pour ça\n",
      "que le rap est un peu d'minutes\n",
      "prends des lois\n",
      "quand le problème de marie-nous, tu sais sans pouce triste\n",
      "j'pense à attraper l'andes\n",
      "dis moi où ça révolutionnent et je croisais à contre-trois quarts d'agonie\n",
      "le début gros sac, j'ai besoin d'm'croiser dans le seffet fait pas la parole que j'ai fait des mots\n",
      "\n",
      "<REFRAIN>\n",
      "\n",
      "est-ce que c'est ma plume te la borge le plus jumbard\n",
      "fier d'écrit\n",
      "\n",
      " <END>\n"
     ]
    }
   ],
   "source": [
    "context_gen = \"voila pourquoi, \"\n",
    "context_encode = [mapping[i] for i in context_gen]\n",
    "context_size = len(context_encode)\n",
    "\n",
    "hid = model.init_hidden(batch_size=1)\n",
    "\n",
    "for i in range(len(struct) - 2):\n",
    "\n",
    "    print()\n",
    "    print(decod_structure[struct[i+1]])\n",
    "\n",
    "    if i == 0 : \n",
    "        context_encode.insert(0,mapping[struct[i+1]])\n",
    "        context_encode.insert(1,mapping[\"\\n\"])\n",
    "        encoded = torch.tensor(context_encode, dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "        print(\"\".join([int2char[i] for i in context_encode[1:]]), end=\"\")\n",
    "\n",
    "        out, hid = model(encoded, hid)\n",
    "        next_input = encoded[:, -1].unsqueeze(0)  # shape (1, 1)\n",
    "\n",
    "    else : \n",
    "        #next_input = torch.tensor(mapping[struct[i+1]],dtype=torch.long).unsqueeze(0)\n",
    "        next_input = torch.tensor(mapping[struct[i+1]],dtype=torch.long).view(1,1)\n",
    "\n",
    "    last_input = 0\n",
    "    first_input = True\n",
    "\n",
    "    while last_input != 12:\n",
    "        with torch.no_grad():\n",
    "            out, hid = model(next_input, hid)   # out shape: (1, 1, vocab_size)\n",
    "\n",
    "            out[0, -1][forbidden_generation] = float(\"-inf\")\n",
    "\n",
    "        # 4. On échantillonne un token\n",
    "            next_token = sample_with_temp_topk(out[0, -1], temperature=0.8, top_k=20)\n",
    "            last_input = next_token.item()\n",
    "\n",
    "        # 5. Conditions d’impression\n",
    "            if first_input and last_input == 12:  # Si début et le modèle sort directement <END>\n",
    "                last_input = 0\n",
    "                continue\n",
    "\n",
    "            elif first_input and last_input == 0:  # Si début et sortie = \\n\n",
    "                first_input = False\n",
    "                forbidden_generation.extend([0])\n",
    "                print(int2char[next_token.item()], end=\"\")\n",
    "\n",
    "            elif next_token.item() != 12:\n",
    "                first_input = False\n",
    "                print(int2char[next_token.item()], end=\"\")\n",
    "\n",
    "                if 0 in forbidden_generation:\n",
    "                    forbidden_generation.pop(-1)\n",
    "\n",
    "        # 6. Préparer la prochaine entrée\n",
    "            next_input = next_token.view(1, 1)\n",
    "\n",
    "print(\"\\n\", decod_structure[struct[-1]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
