{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13220961,"sourceType":"datasetVersion","datasetId":8299981},{"sourceId":595734,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":446043,"modelId":462509}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This notebook will serve as a way to implement character generation RNN ","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport re\nimport numpy as np\nimport pickle\nimport random\nfrom torch.utils.data import random_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:19.560302Z","iopub.execute_input":"2025-10-17T20:51:19.560522Z","iopub.status.idle":"2025-10-17T20:51:23.103015Z","shell.execute_reply.started":"2025-10-17T20:51:19.560501Z","shell.execute_reply":"2025-10-17T20:51:23.102215Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"with open(\"/kaggle/input/rnn-input/encoding_map.pkl\", \"rb\") as f:\n    mapping = pickle.load(f)\n\nmapping[\"PAD\"] = len(mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:23.104410Z","iopub.execute_input":"2025-10-17T20:51:23.104751Z","iopub.status.idle":"2025-10-17T20:51:23.117065Z","shell.execute_reply.started":"2025-10-17T20:51:23.104724Z","shell.execute_reply":"2025-10-17T20:51:23.116382Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"# Decode\nint2char = {i: ch for ch, i in mapping.items()}\nprint(int2char)\n\nnb_char = len(int2char)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:23.117712Z","iopub.execute_input":"2025-10-17T20:51:23.117934Z","iopub.status.idle":"2025-10-17T20:51:23.128673Z","shell.execute_reply.started":"2025-10-17T20:51:23.117916Z","shell.execute_reply":"2025-10-17T20:51:23.127937Z"}},"outputs":[{"name":"stdout","text":"{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '%', 5: '&', 6: \"'\", 7: ')', 8: '+', 9: ',', 10: '-', 11: '.', 12: '/', 13: '0', 14: '1', 15: '2', 16: '3', 17: '4', 18: '5', 19: '6', 20: '7', 21: '8', 22: '9', 23: ':', 24: ';', 25: '?', 26: 'a', 27: 'b', 28: 'c', 29: 'd', 30: 'e', 31: 'f', 32: 'g', 33: 'h', 34: 'i', 35: 'j', 36: 'k', 37: 'l', 38: 'm', 39: 'n', 40: 'o', 41: 'p', 42: 'q', 43: 'r', 44: 's', 45: 't', 46: 'u', 47: 'v', 48: 'w', 49: 'x', 50: 'y', 51: 'z', 52: 'à', 53: 'â', 54: 'ç', 55: 'è', 56: 'é', 57: 'ê', 58: 'ë', 59: 'î', 60: 'ï', 61: 'ô', 62: 'ù', 63: 'û', 64: 'α', 65: 'β', 66: 'γ', 67: 'ε', 68: 'ζ', 69: 'η', 70: 'θ', 71: '€', 72: 'PAD'}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Creation of the dataset","metadata":{}},{"cell_type":"markdown","source":"To increase the randomness during the training :\n\nFor each epoch the entire corpus will have a random specific offset value in order that the model during training doesn't see the exact same text during X epochs.","metadata":{}},{"cell_type":"code","source":"class SongDataset(Dataset):\n    def __init__(self, texts, length_seq, stride, pad_id=mapping[\"PAD\"], use_offset=True):\n        self.samples = []\n        self.length_seq = length_seq\n        self.stride = stride\n        self.pad_id = pad_id\n\n        for text in texts:\n            # --- Sécurité : s'assurer d'un tensor 1D long CPU ---\n            if not isinstance(text, torch.Tensor):\n                text = torch.tensor(text, dtype=torch.long)\n            else:\n                text = text.clone().detach().to(dtype=torch.long, device=\"cpu\").contiguous()\n\n            L = len(text)\n            if L < 2:\n                continue\n\n            offset = torch.randint(0, stride, (1,)).item() if use_offset else 0\n\n            # --- Boucle principale ---\n            for start in range(offset, max(1, L - self.length_seq - 1), self.stride):\n                x_start, x_end = start, start + self.length_seq\n                y_start, y_end = start + 1, start + 1 + self.length_seq\n\n                x = text[x_start:x_end]\n                y = text[y_start:y_end]\n\n                # --- Padding uniforme ---\n                def pad_to_len(seq, pad_id, target_len):\n                    pad_len = target_len - len(seq)\n                    if pad_len > 0:\n                        seq = torch.cat([seq, torch.full((pad_len,), pad_id, dtype=seq.dtype)])\n                    return seq\n\n                x = pad_to_len(x, self.pad_id, self.length_seq)\n                y = pad_to_len(y, self.pad_id, self.length_seq)\n\n                self.samples.append((x, y))\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        return self.samples[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:23.129465Z","iopub.execute_input":"2025-10-17T20:51:23.129748Z","iopub.status.idle":"2025-10-17T20:51:23.145684Z","shell.execute_reply.started":"2025-10-17T20:51:23.129726Z","shell.execute_reply":"2025-10-17T20:51:23.144984Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset_ = np.load(\"/kaggle/input/rnn-input/corpora_encoded.npy\",\"r\")\n\nresult = []\nfor t in dataset_:\n    if t == 64 : \n        current = []\n        current.append(t)\n    elif t == 70:\n        current.append(t)\n        result.append(torch.tensor(current))\n    else :\n        current.append(t)\nif current:  \n    result.append(torch.tensor(current))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:23.146524Z","iopub.execute_input":"2025-10-17T20:51:23.146766Z","iopub.status.idle":"2025-10-17T20:51:26.356980Z","shell.execute_reply.started":"2025-10-17T20:51:23.146744Z","shell.execute_reply":"2025-10-17T20:51:26.356441Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"len_train = int(len(result) * 0.8)\nlen_test = len(result) - len_train\n\ngenerator = torch.Generator().manual_seed(42)\ntrain, test = random_split(result, [len_train, len_test], generator = generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:26.357609Z","iopub.execute_input":"2025-10-17T20:51:26.357787Z","iopub.status.idle":"2025-10-17T20:51:26.370709Z","shell.execute_reply.started":"2025-10-17T20:51:26.357773Z","shell.execute_reply":"2025-10-17T20:51:26.370121Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_ds = SongDataset(train,length_seq=256, stride = 64, use_offset = True)\ntest_ds = SongDataset(test,length_seq=256, stride = 64, use_offset = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:26.372674Z","iopub.execute_input":"2025-10-17T20:51:26.372884Z","iopub.status.idle":"2025-10-17T20:51:26.910649Z","shell.execute_reply.started":"2025-10-17T20:51:26.372868Z","shell.execute_reply":"2025-10-17T20:51:26.910100Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(\"\".join([int2char[i] for i in train_ds[0][0][:256].numpy()]))\nprint()\nprint(\"\".join([int2char[i] for i in train_ds[1][0][:256].numpy()]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:26.911245Z","iopub.execute_input":"2025-10-17T20:51:26.911446Z","iopub.status.idle":"2025-10-17T20:51:26.917512Z","shell.execute_reply.started":"2025-10-17T20:51:26.911429Z","shell.execute_reply":"2025-10-17T20:51:26.916703Z"}},"outputs":[{"name":"stdout","text":"ux le voir\ntu penses sûrement qu'j'suis plus heureux que toi\nrien ne dure tout est éphémère frérot\nj'ai rien à cacher comme les femens\navant j'avais qu'des p'tites pièces comme le passeur d'âme\net là je brunch avec madame à amsterdam\nfaire plaisir à ceux q\n\nn ne dure tout est éphémère frérot\nj'ai rien à cacher comme les femens\navant j'avais qu'des p'tites pièces comme le passeur d'âme\net là je brunch avec madame à amsterdam\nfaire plaisir à ceux qu'on aime ça n'a pas d'prix\npour tout le reste y a ta mastercard\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Creation of Dataloader and co","metadata":{}},{"cell_type":"code","source":"batch_size = 1024\n\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, pin_memory=True, pin_memory_device=\"cuda:0\", shuffle=False, drop_last=True) #Shuffle False because we need the RNN to use previous sequences data to predict next one\ntest_dl = DataLoader(test_ds, batch_size=batch_size, pin_memory=True, pin_memory_device=\"cuda:0\", shuffle=False, drop_last=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:26.918232Z","iopub.execute_input":"2025-10-17T20:51:26.918463Z","iopub.status.idle":"2025-10-17T20:51:26.930156Z","shell.execute_reply.started":"2025-10-17T20:51:26.918444Z","shell.execute_reply":"2025-10-17T20:51:26.929506Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Check the good dataloading and offset validity","metadata":{}},{"cell_type":"code","source":"len(dataset_),len(train_dl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:26.930917Z","iopub.execute_input":"2025-10-17T20:51:26.931111Z","iopub.status.idle":"2025-10-17T20:51:26.945347Z","shell.execute_reply.started":"2025-10-17T20:51:26.931097Z","shell.execute_reply":"2025-10-17T20:51:26.944696Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(3705039, 40)"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## Models","metadata":{}},{"cell_type":"markdown","source":"### Training part","metadata":{}},{"cell_type":"code","source":"class CharRNN(nn.Module):\n    def __init__(self, vocab_size, emb_size, hidden_size, num_layers=1, dropout = 0):\n        super(CharRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=72)\n        self.rnn = nn.RNN(emb_size, hidden_size, num_layers, batch_first=True, dropout = dropout, nonlinearity =\"relu\")\n        self.drop = nn.Dropout(p=dropout)\n        self.ln = nn.LayerNorm(hidden_size)\n        self.fc = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, x, hidden):\n        x = self.drop(self.embedding(x))\n        out, hidden = self.rnn(x, hidden)\n#        out = self.ln(out)\n        out = self.drop(out)\n        out = self.fc(out)                  \n        return out, hidden\n\n    def init_hidden(self, batch_size):\n        return torch.zeros(self.num_layers, batch_size, self.hidden_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:26.946021Z","iopub.execute_input":"2025-10-17T20:51:26.946205Z","iopub.status.idle":"2025-10-17T20:51:26.958159Z","shell.execute_reply.started":"2025-10-17T20:51:26.946191Z","shell.execute_reply":"2025-10-17T20:51:26.957569Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device1 = torch.device(\"cuda:0\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:26.958714Z","iopub.execute_input":"2025-10-17T20:51:26.958877Z","iopub.status.idle":"2025-10-17T20:51:26.970437Z","shell.execute_reply.started":"2025-10-17T20:51:26.958857Z","shell.execute_reply":"2025-10-17T20:51:26.969919Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"embedding_dim = 128\nvocab_size = len(int2char)\nhidden_size = 512\nnum_epoch = 150\n\nnb_step_train = len(train_dl)\nnb_step_test = len(test_dl)\n\nmodel = CharRNN(vocab_size, embedding_dim, hidden_size, num_layers=4, dropout = 0.2).to(device1)\nmodel = torch.compile(model)\n\n#weights = torch.ones(vocab_size).to(device1)\n\n#Structure marker (really important)\n#for p in [\" \", \"\\n\"]:\n#    idx = mapping[p]\n#    weights[idx] = 1.5  \n\n#Ponctuation (important) + part indic\n#for p in [\",\", \".\", \"'\", 'α','β','γ','ε','ζ','η','θ']:\n#    idx = mapping[p]\n#    weights[idx] = 1.25  \n\nloss_fn = nn.CrossEntropyLoss(ignore_index=72)\nval_fn = nn.CrossEntropyLoss(ignore_index=72)\n\nopti = torch.optim.AdamW(model.parameters(), lr=0.002, weight_decay=1e-4)\nsched_warm = torch.optim.lr_scheduler.LinearLR(opti,start_factor=0.2,end_factor=1.0,total_iters=nb_step_train * 5)\nsched_post = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opti, T_0=nb_step_train*10, T_mult=2, eta_min=0.0002) \n#sched_plateau = torch.optim.lr_scheduler.ReduceLROnPlateau(opti,mode=\"max\",factor=0.6,patience=3,min_lr=1e-5,verbose=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:26.971144Z","iopub.execute_input":"2025-10-17T20:51:26.971353Z","iopub.status.idle":"2025-10-17T20:51:31.548483Z","shell.execute_reply.started":"2025-10-17T20:51:26.971332Z","shell.execute_reply":"2025-10-17T20:51:31.547756Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import math\n\n@torch.no_grad()\ndef evaluate_tf1(model, dl, loss_fn, device, vocab_size):\n    \"\"\"Validation with teacher forcing = 1 (parallel, fast). Returns (ppl, acc).\"\"\"\n    model.eval()\n    total_loss = 0.0\n    total_tokens = 0\n    correct = 0\n    total = 0\n\n    for X, Y in dl:\n        X = X.to(device)\n        Y = Y.to(device, dtype=torch.long)\n        bs, sl = X.size(0), X.size(1)\n        hid = model.init_hidden(bs).to(device)\n\n        with torch.amp.autocast(device_type=\"cuda\"):\n            pred, _ = model(X, hid)  # (bs, sl, vocab)\n            loss = loss_fn(pred.view(-1, vocab_size), Y.view(-1))\n\n        total_loss += loss.item() * bs * sl\n        total_tokens += bs * sl\n\n        pred_ids = pred.argmax(dim=-1)\n        correct += (pred_ids == Y).sum().item()\n        total += bs * sl\n\n    ppl = math.exp(total_loss / max(1, total_tokens))\n    acc = correct / max(1, total)\n    return ppl, acc\n\n\n@torch.no_grad()\ndef evaluate_free(model, dl, loss_fn, device):\n    \"\"\"\n    Autoregressive validation (teacher forcing = 0).\n    Steps one token at a time and feeds predictions back in.\n    Returns ppl (computed on next-token NLL).\n    \"\"\"\n    model.eval()\n    total_loss = 0.0\n    total_tokens = 0\n\n    for X, Y in dl:\n        X = X.to(device)\n        Y = Y.to(device, dtype=torch.long)\n        bs, sl = X.size(0), X.size(1)\n        hid = model.init_hidden(bs).to(device)\n\n        # Start with the first input token\n        inp = X[:, :1]  # (bs, 1)\n        for t in range(sl):\n            with torch.amp.autocast(device_type=\"cuda\"):\n                pred, hid = model(inp, hid)          # (bs, 1, vocab)\n                logits = pred[:, -1, :]              # (bs, vocab)\n                loss = loss_fn(logits, Y[:, t])      # CE over current step\n\n            total_loss += loss.item() * bs\n            total_tokens += bs\n\n            # Greedy next-token to feed back in\n            next_token = logits.argmax(dim=-1).unsqueeze(1)  # (bs, 1)\n            inp = next_token\n\n    ppl = math.exp(total_loss / max(1, total_tokens))\n    return ppl\n\ndef sample_with_temp(logits, temp=1.0):\n    probs = (logits / temp).softmax(dim=-1)\n    next_token = torch.multinomial(probs, num_samples=1)\n    return next_token\n\ndef distinct_n_chars(text, n=3):\n    ngrams = [text[i:i+n] for i in range(len(text)-n+1)]\n    return len(set(ngrams)) / max(1, len(ngrams))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:31.549318Z","iopub.execute_input":"2025-10-17T20:51:31.549664Z","iopub.status.idle":"2025-10-17T20:51:31.560299Z","shell.execute_reply.started":"2025-10-17T20:51:31.549640Z","shell.execute_reply":"2025-10-17T20:51:31.559005Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"list_offset = []\nl_tot = []\nteacher_forcing_ratio = 1\nbest_val = float(\"inf\")\n\nscaler = torch.amp.GradScaler()\n\nfor epoch in range(num_epoch):\n\n    # --- Teacher Forcing ratio decay (linear) ---\n#    if epoch % 10 == 0 :\n#        teacher_forcing_ratio = max(0.0, min(1.0, teacher_forcing_ratio - 0.02))\n#        print(f\"\\nEpoch {epoch} | Teacher forcing ratio = {teacher_forcing_ratio:.2f}\")\n\n    model.train()\n\n    # -------------- TRAIN LOOP --------------\n    train_loss = 0.0\n    train_loss_sum = 0.0\n    train_tokens = 0\n\n    for X, Y in iter(train_dl):\n        hid = model.init_hidden(batch_size).to(device1)\n        X = X.to(device1)\n        Y = Y.to(device1, dtype=torch.long)\n        opti.zero_grad(set_to_none=True)\n\n        if teacher_forcing_ratio == 1.0:\n            with torch.amp.autocast(device_type=\"cuda\"):\n                pred, hid = model(X, hid)\n                loss = loss_fn(pred.view(-1, vocab_size), Y.view(-1))\n        else:\n            # ---- Pass 1: forward with TF=1 (parallel) ----\n            with torch.no_grad(), torch.amp.autocast(device_type=\"cuda\"):\n                pred_tf, _ = model(X, hid)     # (batch, seq_len, vocab)\n            pred_tokens = pred_tf.argmax(dim=-1)  # (batch, seq_len)\n\n            # ---- Random mask for partial TF ----\n            mask = (torch.rand_like(X.float()) < teacher_forcing_ratio)\n            X_mixed = torch.where(mask, X, pred_tokens)\n\n            # ---- Pass 2: forward with partial TF ----\n            with torch.amp.autocast(device_type=\"cuda\"):\n                pred, hid = model(X_mixed, hid)\n                loss = loss_fn(pred.view(-1, vocab_size), Y.view(-1))\n\n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n        scaler.step(opti)\n        scaler.update()\n\n        # book-keeping\n        train_loss += loss.detach().item()\n        train_ppl = math.exp(train_loss/nb_step_train)\n        if epoch < 5:\n            sched_warm.step()\n        else:\n            sched_post.step()\n\n        if getattr(sched_post, \"T_cur\", None) == 0 and epoch > 5:\n            sched_post.base_lrs[0] *= 0.85\n            # sched_post.eta_min *= 1.25\n            print(f\"Decrease {sched_post.base_lrs[0]}, {sched_post.eta_min}\")\n\n    # -------------- VALIDATION --------------\n    val_ppl_tf1, val_acc = evaluate_tf1(model, test_dl, val_fn, device1, vocab_size)\n    val_ppl_free = evaluate_free(model, test_dl, val_fn, device1)\n\n    print(\n        f\"Epoch {epoch} | \"\n        f\"Train PPL: {train_ppl:.3f} | \"\n        f\"Val PPL (TF=1): {val_ppl_tf1:.3f} | \"\n        f\"Val PPL (free): {val_ppl_free:.3f} | \"\n        f\"Val Acc: {val_acc:.3f}\"\n    )\n\n    # --------- Sample generation + diversity metrics ---------\n    if epoch % 10 == 0 :\n        model.eval()\n        with torch.no_grad():\n        # prends les 5 premiers chars du batch courant comme seed\n            start = X[0:1, :20]  \n            hid_gen = model.init_hidden(1).to(device1)\n            inp = start\n\n            gen_chars = []\n            for t in range(200):  # génère 200 caractères\n                pred, hid_gen = model(inp, hid_gen)\n                logits = pred[:, -1, :]  # dernier pas\n                next_char = sample_with_temp(logits, temp=0.6)\n                gen_chars.append(int2char[next_char.item()])\n                inp = next_char # feed back\n\n            gen_text = \"\".join(gen_chars)\n\n        d2 = distinct_n_chars(gen_text, n=2)\n        d3 = distinct_n_chars(gen_text, n=3)\n    \n        print(\"\\n=== Initial text ===\")\n        print(\"\".join([int2char[i] for i in X[0:1,:].squeeze(0).tolist()]))\n        print(\"\\n=== Sample Generation ===\")\n        print(gen_text[:200])  # affiche les 200 premiers chars\n        print(f\"Distinct-2: {d2:.3f} | Distinct-3: {d3:.3f}\", end=\"\\n\")\n\n    # Record accuracy\n    l_tot.append(val_ppl_tf1)\n    if val_ppl_tf1 < best_val :\n        best_val = val_ppl_tf1\n        torch.save(\n                {\n                    \"epoch\": epoch,\n                    \"model_state_dict\": model.state_dict(),\n                    \"optimizer_state_dict\": opti.state_dict(),\n                    \"scheduler_state_dict\": sched_post.state_dict(),\n                    \"val_ppl\": val_ppl_tf1,\n                },\n                \"model_forced\",\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T20:51:31.561111Z","iopub.execute_input":"2025-10-17T20:51:31.561353Z","execution_failed":"2025-10-17T21:16:35.386Z"}},"outputs":[{"name":"stdout","text":"Epoch 0 | Train PPL: 19.439 | Val PPL (TF=1): 10.996 | Val PPL (free): 70.999 | Val Acc: 0.298\n\n=== Initial text ===\n non, oui, oui; oui et non\n/ε\nγ\nle temps rend malheureux les gens comme rer, rer\ncombien perdent leur religion comme rem, rem?\nvu qu'le monde parait irréel même irl, irl\nj'essaye de voir en eux comme irm\nje veux, veux, veux, veux mettre un trait d'union\nfe\n\n=== Sample Generation ===\nmes pand mais qur dait fres ç'mass la on m'ante je cormis me an pantes enx j'aus\nd'maraste t'an la m'ais c'aste mante à\np'ra d've fout jans bont do sout anton le pans d'te de mant nou ce dont d'an ja \nDistinct-2: 0.447 | Distinct-3: 0.747\nEpoch 1 | Train PPL: 9.566 | Val PPL (TF=1): 7.701 | Val PPL (free): 303.023 | Val Acc: 0.389\nEpoch 2 | Train PPL: 7.311 | Val PPL (TF=1): 6.284 | Val PPL (free): 142.110 | Val Acc: 0.444\nEpoch 3 | Train PPL: 6.259 | Val PPL (TF=1): 5.573 | Val PPL (free): 246.475 | Val Acc: 0.474\nEpoch 4 | Train PPL: 5.693 | Val PPL (TF=1): 5.171 | Val PPL (free): 288.340 | Val Acc: 0.494\nEpoch 5 | Train PPL: 5.165 | Val PPL (TF=1): 4.774 | Val PPL (free): 577.987 | Val Acc: 0.516\nEpoch 6 | Train PPL: 4.941 | Val PPL (TF=1): 4.612 | Val PPL (free): 577.545 | Val Acc: 0.525\nEpoch 7 | Train PPL: 4.793 | Val PPL (TF=1): 4.487 | Val PPL (free): 742.453 | Val Acc: 0.534\nEpoch 8 | Train PPL: 4.680 | Val PPL (TF=1): 4.402 | Val PPL (free): 572.353 | Val Acc: 0.539\nEpoch 9 | Train PPL: 4.596 | Val PPL (TF=1): 4.341 | Val PPL (free): 653.995 | Val Acc: 0.543\nEpoch 10 | Train PPL: 4.532 | Val PPL (TF=1): 4.293 | Val PPL (free): 654.279 | Val Acc: 0.546\n\n=== Initial text ===\n non, oui, oui; oui et non\n/ε\nγ\nle temps rend malheureux les gens comme rer, rer\ncombien perdent leur religion comme rem, rem?\nvu qu'le monde parait irréel même irl, irl\nj'essaye de voir en eux comme irm\nje veux, veux, veux, veux mettre un trait d'union\nfe\n\n=== Sample Generation ===\non a la haine et l'aller toutes les cons pour attendant, le pay mais j'suis pas la drogue du mar\n/ζ\nε\npas beaucoup d'compte et si c'est c'que j'ai peur de moi, tous les filles\nc'est la chaud\nsouvent l\nDistinct-2: 0.558 | Distinct-3: 0.828\nEpoch 11 | Train PPL: 4.481 | Val PPL (TF=1): 4.251 | Val PPL (free): 703.359 | Val Acc: 0.549\nEpoch 12 | Train PPL: 4.441 | Val PPL (TF=1): 4.226 | Val PPL (free): 754.833 | Val Acc: 0.551\nEpoch 13 | Train PPL: 4.414 | Val PPL (TF=1): 4.207 | Val PPL (free): 664.394 | Val Acc: 0.552\nDecrease 0.0017, 0.0002\nEpoch 14 | Train PPL: 4.394 | Val PPL (TF=1): 4.199 | Val PPL (free): 814.162 | Val Acc: 0.553\nEpoch 15 | Train PPL: 4.424 | Val PPL (TF=1): 4.198 | Val PPL (free): 1015.529 | Val Acc: 0.554\nEpoch 16 | Train PPL: 4.365 | Val PPL (TF=1): 4.151 | Val PPL (free): 784.835 | Val Acc: 0.556\nEpoch 17 | Train PPL: 4.315 | Val PPL (TF=1): 4.133 | Val PPL (free): 877.094 | Val Acc: 0.558\nEpoch 18 | Train PPL: 4.268 | Val PPL (TF=1): 4.085 | Val PPL (free): 1075.184 | Val Acc: 0.561\nEpoch 19 | Train PPL: 4.227 | Val PPL (TF=1): 4.068 | Val PPL (free): 1066.440 | Val Acc: 0.563\nEpoch 20 | Train PPL: 4.187 | Val PPL (TF=1): 4.042 | Val PPL (free): 1109.866 | Val Acc: 0.564\n\n=== Initial text ===\n non, oui, oui; oui et non\n/ε\nγ\nle temps rend malheureux les gens comme rer, rer\ncombien perdent leur religion comme rem, rem?\nvu qu'le monde parait irréel même irl, irl\nj'essaye de voir en eux comme irm\nje veux, veux, veux, veux mettre un trait d'union\nfe\n\n=== Sample Generation ===\ntout c'qu'on passe pas d'grands rêves et les tours d'artistes\nsur les c'est le bonheur qui va pas d'marine\nne vous passe des captes les doutes de la force pour le capré dans la pute\net je veux pas rem\nDistinct-2: 0.482 | Distinct-3: 0.722\nEpoch 21 | Train PPL: 4.152 | Val PPL (TF=1): 4.012 | Val PPL (free): 1031.980 | Val Acc: 0.566\nEpoch 22 | Train PPL: 4.124 | Val PPL (TF=1): 3.981 | Val PPL (free): 715.631 | Val Acc: 0.568\nEpoch 23 | Train PPL: 4.096 | Val PPL (TF=1): 3.971 | Val PPL (free): 885.117 | Val Acc: 0.569\nEpoch 24 | Train PPL: 4.070 | Val PPL (TF=1): 3.950 | Val PPL (free): 880.893 | Val Acc: 0.571\nEpoch 25 | Train PPL: 4.049 | Val PPL (TF=1): 3.942 | Val PPL (free): 956.695 | Val Acc: 0.571\nEpoch 26 | Train PPL: 4.029 | Val PPL (TF=1): 3.919 | Val PPL (free): 724.611 | Val Acc: 0.573\nEpoch 27 | Train PPL: 4.011 | Val PPL (TF=1): 3.915 | Val PPL (free): 1026.826 | Val Acc: 0.573\nEpoch 28 | Train PPL: 3.995 | Val PPL (TF=1): 3.905 | Val PPL (free): 1275.247 | Val Acc: 0.574\nEpoch 29 | Train PPL: 3.980 | Val PPL (TF=1): 3.895 | Val PPL (free): 1251.406 | Val Acc: 0.575\nEpoch 30 | Train PPL: 3.968 | Val PPL (TF=1): 3.884 | Val PPL (free): 1247.791 | Val Acc: 0.576\n\n=== Initial text ===\n non, oui, oui; oui et non\n/ε\nγ\nle temps rend malheureux les gens comme rer, rer\ncombien perdent leur religion comme rem, rem?\nvu qu'le monde parait irréel même irl, irl\nj'essaye de voir en eux comme irm\nje veux, veux, veux, veux mettre un trait d'union\nfe\n\n=== Sample Generation ===\nau lieu d'mes propres nerfs, on est sur les choses, j'devenir les sourires\ntu parles qu'au fond d'pour le compas à la ferme de l'occasion qu'ça sert de mes gars faut qu'on s'appelle les platties sont \nDistinct-2: 0.533 | Distinct-3: 0.823\nEpoch 31 | Train PPL: 3.957 | Val PPL (TF=1): 3.876 | Val PPL (free): 1223.917 | Val Acc: 0.576\nEpoch 32 | Train PPL: 3.948 | Val PPL (TF=1): 3.874 | Val PPL (free): 1452.526 | Val Acc: 0.576\nEpoch 33 | Train PPL: 3.941 | Val PPL (TF=1): 3.871 | Val PPL (free): 1510.465 | Val Acc: 0.577\nDecrease 0.0014449999999999999, 0.0002\nEpoch 34 | Train PPL: 3.936 | Val PPL (TF=1): 3.868 | Val PPL (free): 1429.285 | Val Acc: 0.577\nEpoch 35 | Train PPL: 3.969 | Val PPL (TF=1): 3.886 | Val PPL (free): 1015.525 | Val Acc: 0.576\nEpoch 36 | Train PPL: 3.951 | Val PPL (TF=1): 3.878 | Val PPL (free): 1293.467 | Val Acc: 0.576\nEpoch 37 | Train PPL: 3.930 | Val PPL (TF=1): 3.859 | Val PPL (free): 1227.920 | Val Acc: 0.578\nEpoch 38 | Train PPL: 3.914 | Val PPL (TF=1): 3.844 | Val PPL (free): 832.824 | Val Acc: 0.578\nEpoch 39 | Train PPL: 3.895 | Val PPL (TF=1): 3.830 | Val PPL (free): 235.679 | Val Acc: 0.580\nEpoch 40 | Train PPL: 3.881 | Val PPL (TF=1): 3.825 | Val PPL (free): 890.559 | Val Acc: 0.580\n\n=== Initial text ===\n non, oui, oui; oui et non\n/ε\nγ\nle temps rend malheureux les gens comme rer, rer\ncombien perdent leur religion comme rem, rem?\nvu qu'le monde parait irréel même irl, irl\nj'essaye de voir en eux comme irm\nje veux, veux, veux, veux mettre un trait d'union\nfe\n\n=== Sample Generation ===\nj'ai pas l'goût d'un action\nen schnave\nles autres et des enfants comme les sommes à la miff et puis si c'est des mailles dans l'connard de marcher\net qu'on s'entends pas d'la calère\npour les mêmes jou\nDistinct-2: 0.558 | Distinct-3: 0.818\nEpoch 41 | Train PPL: nan | Val PPL (TF=1): 3.844 | Val PPL (free): 390.956 | Val Acc: 0.579\nEpoch 42 | Train PPL: 3.882 | Val PPL (TF=1): 3.828 | Val PPL (free): 2110.804 | Val Acc: 0.580\nEpoch 43 | Train PPL: 3.866 | Val PPL (TF=1): 3.827 | Val PPL (free): 3764.664 | Val Acc: 0.580\nEpoch 44 | Train PPL: 3.847 | Val PPL (TF=1): 3.822 | Val PPL (free): 2498.868 | Val Acc: 0.581\nEpoch 45 | Train PPL: 3.818 | Val PPL (TF=1): 3.801 | Val PPL (free): 2357.885 | Val Acc: 0.582\nEpoch 46 | Train PPL: 3.801 | Val PPL (TF=1): 3.783 | Val PPL (free): 884.125 | Val Acc: 0.584\nEpoch 47 | Train PPL: 3.785 | Val PPL (TF=1): 3.798 | Val PPL (free): 1899.174 | Val Acc: 0.584\nEpoch 48 | Train PPL: 3.764 | Val PPL (TF=1): 3.773 | Val PPL (free): 2513.508 | Val Acc: 0.585\nEpoch 49 | Train PPL: 3.753 | Val PPL (TF=1): 3.765 | Val PPL (free): 448.827 | Val Acc: 0.586\nEpoch 50 | Train PPL: 3.735 | Val PPL (TF=1): 3.760 | Val PPL (free): 922.594 | Val Acc: 0.586\n\n=== Initial text ===\n non, oui, oui; oui et non\n/ε\nγ\nle temps rend malheureux les gens comme rer, rer\ncombien perdent leur religion comme rem, rem?\nvu qu'le monde parait irréel même irl, irl\nj'essaye de voir en eux comme irm\nje veux, veux, veux, veux mettre un trait d'union\nfe\n\n=== Sample Generation ===\nj'ai mes addictions\ncomme un mec est coupé de coin\nj'ai des grands partis tous les deux contrôleurs, les paroles et les petits brillent\nambiance le drapeau a rien d'autres qui dégueules\nj'ai peur de b\nDistinct-2: 0.553 | Distinct-3: 0.828\nEpoch 51 | Train PPL: 3.718 | Val PPL (TF=1): 3.762 | Val PPL (free): 491.750 | Val Acc: 0.587\nEpoch 52 | Train PPL: 3.704 | Val PPL (TF=1): 3.752 | Val PPL (free): 887.268 | Val Acc: 0.587\nEpoch 53 | Train PPL: nan | Val PPL (TF=1): 3.768 | Val PPL (free): 405.301 | Val Acc: 0.586\nEpoch 54 | Train PPL: 3.703 | Val PPL (TF=1): 3.739 | Val PPL (free): 2635.800 | Val Acc: 0.587\nEpoch 55 | Train PPL: 3.685 | Val PPL (TF=1): 3.734 | Val PPL (free): 1289.156 | Val Acc: 0.589\nEpoch 56 | Train PPL: 3.668 | Val PPL (TF=1): 3.756 | Val PPL (free): 1118.316 | Val Acc: 0.588\nEpoch 57 | Train PPL: 3.651 | Val PPL (TF=1): 3.745 | Val PPL (free): 1882.083 | Val Acc: 0.589\nEpoch 58 | Train PPL: 3.638 | Val PPL (TF=1): 3.714 | Val PPL (free): 2281.237 | Val Acc: 0.590\nEpoch 59 | Train PPL: 3.629 | Val PPL (TF=1): 3.716 | Val PPL (free): 1976.052 | Val Acc: 0.590\nEpoch 60 | Train PPL: 3.614 | Val PPL (TF=1): 3.703 | Val PPL (free): 435.714 | Val Acc: 0.591\n\n=== Initial text ===\n non, oui, oui; oui et non\n/ε\nγ\nle temps rend malheureux les gens comme rer, rer\ncombien perdent leur religion comme rem, rem?\nvu qu'le monde parait irréel même irl, irl\nj'essaye de voir en eux comme irm\nje veux, veux, veux, veux mettre un trait d'union\nfe\n\n=== Sample Generation ===\ndans l'coup d'or d'l'argent d'bourgeois, j'en ai déjà rien de produit d'ça\nj'suis qu'un peu travailleur de maladroit pour me voir papa\nrappeur de merde, j'ai pris le fond de la rue et la maille\nj'suis\nDistinct-2: 0.533 | Distinct-3: 0.803\nEpoch 61 | Train PPL: 3.609 | Val PPL (TF=1): 3.700 | Val PPL (free): 1071.152 | Val Acc: 0.590\nEpoch 62 | Train PPL: 3.594 | Val PPL (TF=1): 3.686 | Val PPL (free): 1124.194 | Val Acc: 0.592\nEpoch 63 | Train PPL: 3.584 | Val PPL (TF=1): 3.683 | Val PPL (free): 2671.261 | Val Acc: 0.592\nEpoch 64 | Train PPL: 3.575 | Val PPL (TF=1): 3.681 | Val PPL (free): 2644.516 | Val Acc: 0.592\nEpoch 65 | Train PPL: 3.567 | Val PPL (TF=1): 3.679 | Val PPL (free): 3191.558 | Val Acc: 0.592\nEpoch 66 | Train PPL: 3.559 | Val PPL (TF=1): 3.678 | Val PPL (free): 2497.172 | Val Acc: 0.593\nEpoch 67 | Train PPL: 3.552 | Val PPL (TF=1): 3.676 | Val PPL (free): 3301.883 | Val Acc: 0.593\nEpoch 68 | Train PPL: 3.544 | Val PPL (TF=1): 3.675 | Val PPL (free): 3581.685 | Val Acc: 0.593\nEpoch 69 | Train PPL: 3.538 | Val PPL (TF=1): 3.670 | Val PPL (free): 4205.938 | Val Acc: 0.594\nEpoch 70 | Train PPL: 3.533 | Val PPL (TF=1): 3.668 | Val PPL (free): 3281.300 | Val Acc: 0.594\n\n=== Initial text ===\n non, oui, oui; oui et non\n/ε\nγ\nle temps rend malheureux les gens comme rer, rer\ncombien perdent leur religion comme rem, rem?\nvu qu'le monde parait irréel même irl, irl\nj'essaye de voir en eux comme irm\nje veux, veux, veux, veux mettre un trait d'union\nfe\n\n=== Sample Generation ===\nj'suis là-bas\non est là pour les femmes à faire ta vie\npas d'leur casse-moi l'amour de la came et des boucles, faut qu'tu cherches des thunes dans l'sourire de l'amour dans l'coeur, au premier pote j'\nDistinct-2: 0.518 | Distinct-3: 0.788\nEpoch 71 | Train PPL: 3.528 | Val PPL (TF=1): 3.670 | Val PPL (free): 1844.535 | Val Acc: 0.594\nEpoch 72 | Train PPL: 3.522 | Val PPL (TF=1): 3.669 | Val PPL (free): 7492.533 | Val Acc: 0.594\nEpoch 73 | Train PPL: 3.519 | Val PPL (TF=1): 3.668 | Val PPL (free): 3513.222 | Val Acc: 0.594\nDecrease 0.00122825, 0.0002\nEpoch 74 | Train PPL: 3.515 | Val PPL (TF=1): 3.667 | Val PPL (free): 3424.851 | Val Acc: 0.594\nEpoch 75 | Train PPL: 3.570 | Val PPL (TF=1): 3.702 | Val PPL (free): 459.651 | Val Acc: 0.592\nEpoch 76 | Train PPL: 3.560 | Val PPL (TF=1): 3.685 | Val PPL (free): 1285.362 | Val Acc: 0.593\nEpoch 77 | Train PPL: 3.553 | Val PPL (TF=1): 3.695 | Val PPL (free): 2180.300 | Val Acc: 0.593\nEpoch 78 | Train PPL: 3.545 | Val PPL (TF=1): 3.704 | Val PPL (free): 1293.409 | Val Acc: 0.593\nEpoch 79 | Train PPL: 3.536 | Val PPL (TF=1): 3.689 | Val PPL (free): 2663.084 | Val Acc: 0.593\nEpoch 80 | Train PPL: 3.523 | Val PPL (TF=1): 3.685 | Val PPL (free): 1440.206 | Val Acc: 0.593\n\n=== Initial text ===\n non, oui, oui; oui et non\n/ε\nγ\nle temps rend malheureux les gens comme rer, rer\ncombien perdent leur religion comme rem, rem?\nvu qu'le monde parait irréel même irl, irl\nj'essaye de voir en eux comme irm\nje veux, veux, veux, veux mettre un trait d'union\nfe\n\n=== Sample Generation ===\nj'suis pas comme ça, le monde assez d'chansons\nj'crois qu'c'est la fumée d'un train de ma place de ta chance, j'ai tout fait pour tout droit d'mes fautes\nj'ai ma mission sera comme prox de combat sans\nDistinct-2: 0.508 | Distinct-3: 0.818\nEpoch 81 | Train PPL: 3.514 | Val PPL (TF=1): 3.703 | Val PPL (free): 1535.341 | Val Acc: 0.593\nEpoch 82 | Train PPL: 3.510 | Val PPL (TF=1): 3.696 | Val PPL (free): 1686.372 | Val Acc: 0.594\nEpoch 83 | Train PPL: 3.500 | Val PPL (TF=1): 3.686 | Val PPL (free): 482.232 | Val Acc: 0.594\nEpoch 84 | Train PPL: 3.497 | Val PPL (TF=1): 3.691 | Val PPL (free): 1989.958 | Val Acc: 0.593\nEpoch 85 | Train PPL: 3.495 | Val PPL (TF=1): 3.676 | Val PPL (free): 2220.029 | Val Acc: 0.594\nEpoch 86 | Train PPL: 3.484 | Val PPL (TF=1): 3.670 | Val PPL (free): 1359.245 | Val Acc: 0.594\nEpoch 87 | Train PPL: 3.471 | Val PPL (TF=1): 3.669 | Val PPL (free): 1106.641 | Val Acc: 0.595\nEpoch 88 | Train PPL: 3.461 | Val PPL (TF=1): 3.671 | Val PPL (free): 971.465 | Val Acc: 0.595\nEpoch 89 | Train PPL: 3.463 | Val PPL (TF=1): 3.658 | Val PPL (free): 1255.637 | Val Acc: 0.595\nEpoch 90 | Train PPL: 3.456 | Val PPL (TF=1): 3.668 | Val PPL (free): 1290.694 | Val Acc: 0.595\n\n=== Initial text ===\n non, oui, oui; oui et non\n/ε\nγ\nle temps rend malheureux les gens comme rer, rer\ncombien perdent leur religion comme rem, rem?\nvu qu'le monde parait irréel même irl, irl\nj'essaye de voir en eux comme irm\nje veux, veux, veux, veux mettre un trait d'union\nfe\n\n=== Sample Generation ===\net non, non, non\nj'fais des putes à niquer une nouvelle face aux proches restent que les problèmes de pile ou face\nj'ai des bleus sauvages\nle ciel est aller sous une porte de c'qu'on me donne bien les\nDistinct-2: 0.503 | Distinct-3: 0.788\nEpoch 91 | Train PPL: 3.452 | Val PPL (TF=1): 3.693 | Val PPL (free): 2690.401 | Val Acc: 0.594\nEpoch 92 | Train PPL: 3.443 | Val PPL (TF=1): 3.673 | Val PPL (free): 5429.806 | Val Acc: 0.595\nEpoch 93 | Train PPL: 3.437 | Val PPL (TF=1): 3.702 | Val PPL (free): 2971.945 | Val Acc: 0.595\nEpoch 94 | Train PPL: 3.441 | Val PPL (TF=1): 3.685 | Val PPL (free): 1629.983 | Val Acc: 0.594\nEpoch 95 | Train PPL: 3.435 | Val PPL (TF=1): 3.655 | Val PPL (free): 1707.055 | Val Acc: 0.595\nEpoch 96 | Train PPL: 3.436 | Val PPL (TF=1): 3.668 | Val PPL (free): 1457.851 | Val Acc: 0.595\nEpoch 97 | Train PPL: 3.414 | Val PPL (TF=1): 3.661 | Val PPL (free): 1843.962 | Val Acc: 0.596\nEpoch 98 | Train PPL: 3.401 | Val PPL (TF=1): 3.673 | Val PPL (free): 2746.606 | Val Acc: 0.597\nEpoch 99 | Train PPL: 3.399 | Val PPL (TF=1): 3.681 | Val PPL (free): 3841.309 | Val Acc: 0.595\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"Val PPL (TF=1): 3.756 ","metadata":{}}]}