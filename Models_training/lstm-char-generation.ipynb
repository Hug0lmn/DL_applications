{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13207948,"sourceType":"datasetVersion","datasetId":8299981}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This notebook will serve as a way to implement character generation LSTM and other implementation","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport re\nimport numpy as np\nimport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:49:59.841504Z","iopub.execute_input":"2025-09-29T13:49:59.841767Z","iopub.status.idle":"2025-09-29T13:50:06.490478Z","shell.execute_reply.started":"2025-09-29T13:49:59.841740Z","shell.execute_reply":"2025-09-29T13:50:06.489672Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"with open(\"/kaggle/input/rnn-input/encoding_map.pkl\", \"rb\") as f:\n    mapping = pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:06.491200Z","iopub.execute_input":"2025-09-29T13:50:06.491458Z","iopub.status.idle":"2025-09-29T13:50:06.498770Z","shell.execute_reply.started":"2025-09-29T13:50:06.491441Z","shell.execute_reply":"2025-09-29T13:50:06.498129Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"# Decode\nint2char = {i: ch for ch, i in mapping.items()}\nprint(int2char)\n\nnb_char = len(int2char)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:06.500112Z","iopub.execute_input":"2025-09-29T13:50:06.500309Z","iopub.status.idle":"2025-09-29T13:50:06.512513Z","shell.execute_reply.started":"2025-09-29T13:50:06.500294Z","shell.execute_reply":"2025-09-29T13:50:06.512021Z"}},"outputs":[{"name":"stdout","text":"{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '%', 5: '&', 6: \"'\", 7: '+', 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: ';', 24: '?', 25: 'A', 26: 'B', 27: 'C', 28: 'D', 29: 'E', 30: 'F', 31: 'G', 32: 'H', 33: 'I', 34: 'J', 35: 'K', 36: 'L', 37: 'M', 38: 'N', 39: 'O', 40: 'P', 41: 'Q', 42: 'R', 43: 'S', 44: 'T', 45: 'U', 46: 'V', 47: 'W', 48: 'X', 49: 'Y', 50: 'Z', 51: 'a', 52: 'b', 53: 'c', 54: 'd', 55: 'e', 56: 'f', 57: 'g', 58: 'h', 59: 'i', 60: 'j', 61: 'k', 62: 'l', 63: 'm', 64: 'n', 65: 'o', 66: 'p', 67: 'q', 68: 'r', 69: 's', 70: 't', 71: 'u', 72: 'v', 73: 'w', 74: 'x', 75: 'y', 76: 'z', 77: 'À', 78: 'Ç', 79: 'É', 80: 'Ê', 81: 'à', 82: 'â', 83: 'ç', 84: 'è', 85: 'é', 86: 'ê', 87: 'ë', 88: 'î', 89: 'ï', 90: 'ô', 91: 'ù', 92: 'û', 93: 'Ā', 94: 'ū', 95: 'α', 96: 'β', 97: 'γ', 98: 'ε', 99: 'ζ', 100: 'η', 101: 'θ', 102: 'τ'}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Creation of the dataset","metadata":{}},{"cell_type":"markdown","source":"To increase the randomness during the training :\n\nFor each epoch the entire corpus will have a random specific offset value in order that the model during training doesn't see the exact same text during X epochs.","metadata":{}},{"cell_type":"code","source":"class CharDataset(Dataset) :\n    def __init__(self,text,length_seq) :\n        self.text = text\n        self.length_seq = length_seq\n        self.max_start = len(self.text) - length_seq - 1\n        self.offset = 0\n        \n    def set_offset(self, offset) :\n        self.offset = offset\n        \n    def __len__(self) :\n        return self.max_start\n\n    def __getitem__(self, i) :\n        s = (i + self.offset) % self.max_start\n        x = torch.from_numpy(self.text[s:s+self.length_seq])\n        y = torch.from_numpy(self.text[s+1:s+self.length_seq+1])\n        return x, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:06.513327Z","iopub.execute_input":"2025-09-29T13:50:06.513563Z","iopub.status.idle":"2025-09-29T13:50:06.531599Z","shell.execute_reply.started":"2025-09-29T13:50:06.513542Z","shell.execute_reply":"2025-09-29T13:50:06.530912Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"seq_length = 250\ndataset_ = np.load(\"/kaggle/input/rnn-input/corpora_encoded.npy\",\"r\")\nlen_train = int(len(dataset_)*0.85)\ntrain = dataset_[:len_train]\ntest = dataset_[len_train:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:06.532210Z","iopub.execute_input":"2025-09-29T13:50:06.532378Z","iopub.status.idle":"2025-09-29T13:50:06.559305Z","shell.execute_reply.started":"2025-09-29T13:50:06.532365Z","shell.execute_reply":"2025-09-29T13:50:06.558555Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_ds = CharDataset(train,length_seq=seq_length)\ntest_ds = CharDataset(test,length_seq=seq_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:06.559967Z","iopub.execute_input":"2025-09-29T13:50:06.560127Z","iopub.status.idle":"2025-09-29T13:50:06.563412Z","shell.execute_reply.started":"2025-09-29T13:50:06.560113Z","shell.execute_reply":"2025-09-29T13:50:06.562775Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(train_ds[0][0])\nprint(\"\".join([int2char[i] for i in train_ds[0][0][:seq_length].numpy()]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:06.564137Z","iopub.execute_input":"2025-09-29T13:50:06.564596Z","iopub.status.idle":"2025-09-29T13:50:06.643760Z","shell.execute_reply.started":"2025-09-29T13:50:06.564579Z","shell.execute_reply":"2025-09-29T13:50:06.642943Z"}},"outputs":[{"name":"stdout","text":"tensor([95,  0,  0, 96,  0, 29, 58,  8,  1, 55, 58,  0, 29, 58,  0, 11, 96,  0,\n        97,  0, 37, 65, 59,  8,  1, 60,  6, 51, 59,  1, 66, 51, 69,  1, 54,  6,\n        70, 65, 71, 68,  1, 52, 71, 69,  1, 64, 59,  1, 62, 51,  1, 53, 51, 68,\n        68, 59, 84, 68, 55,  1, 54,  6, 43, 65, 66, 68, 51, 64, 65,  0, 34,  6,\n        69, 71, 59, 69,  1, 51, 72, 55, 53,  1, 62,  6, 51, 63, 59,  1, 51, 71,\n         1, 27, 65, 71, 68, 69,  1, 34, 71,  1, 65, 71,  1, 51, 71,  1, 40, 68,\n        51, 54, 65,  0, 29, 64, 70, 68, 55,  1, 66, 65, 70, 55, 69,  8,  1, 65,\n        64,  1, 51,  1, 68, 59, 55, 64,  1, 81,  1, 66, 51, 68, 70,  1, 62, 51,\n         1, 52, 59, 53, 68, 51, 72, 55,  1, 55, 70,  1, 62,  6, 55, 64, 70, 68,\n        55, 66, 68, 55, 64, 55, 71, 68, 59, 51, 70,  0, 49,  1, 51,  1, 68, 59,\n        55, 64,  1, 67, 71, 59,  1, 69,  6, 65, 56, 56, 68, 55,  1, 81,  1, 64,\n        65, 71, 69,  0, 37, 86, 63, 55,  1, 63, 51,  1, 66, 68, 65, 66, 68, 55,\n         1, 64, 51, 64, 51,  1, 69, 55,  1, 63, 65, 67, 71, 55,  1, 54, 55,  1,\n        63, 65, 59,  0, 41, 71, 51, 64, 54,  1, 60,  6, 62, 71, 59,  1])\nα\n\nβ\nEh, eh\nEh\n/β\nγ\nMoi, j'ai pas d'tour bus ni la carrière d'Soprano\nJ'suis avec l'ami au Cours Ju ou au Prado\nEntre potes, on a rien à part la bicrave et l'entrepreneuriat\nY a rien qui s'offre à nous\nMême ma propre nana se moque de moi\nQuand j'lui \n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/303235149.py:16: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n  x = torch.from_numpy(self.text[s:s+self.length_seq])\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Creation of Dataloader and co","metadata":{}},{"cell_type":"code","source":"batch_size = 2048\n\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, pin_memory=True, pin_memory_device=\"cuda:0\", \n                        num_workers=4, prefetch_factor=4, shuffle=False, drop_last=True) #Shuffle False because we need the RNN to use previous sequences data to predict next one\ntest_dl = DataLoader(test_ds, batch_size=batch_size, pin_memory=True, pin_memory_device=\"cuda:0\", \n                       num_workers=2, prefetch_factor=2, shuffle=False, drop_last=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:06.644357Z","iopub.execute_input":"2025-09-29T13:50:06.644530Z","iopub.status.idle":"2025-09-29T13:50:06.648930Z","shell.execute_reply.started":"2025-09-29T13:50:06.644516Z","shell.execute_reply":"2025-09-29T13:50:06.648192Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Check the good dataloading and offset validity","metadata":{}},{"cell_type":"code","source":"for i in train_dl :\n    print(i[0])\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:06.651071Z","iopub.execute_input":"2025-09-29T13:50:06.651687Z","iopub.status.idle":"2025-09-29T13:50:07.261880Z","shell.execute_reply.started":"2025-09-29T13:50:06.651662Z","shell.execute_reply":"2025-09-29T13:50:07.260940Z"}},"outputs":[{"name":"stdout","text":"tensor([[95,  0,  0,  ..., 71, 59,  1],\n        [ 0,  0, 96,  ..., 59,  1, 51],\n        [ 0, 96,  0,  ...,  1, 51, 59],\n        ...,\n        [70, 69,  1,  ..., 69,  1, 66],\n        [69,  1, 70,  ...,  1, 66, 65],\n        [ 1, 70, 55,  ..., 66, 65, 71]])\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"train_ds.set_offset(1)\nnext(iter(train_dl))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:07.262894Z","iopub.execute_input":"2025-09-29T13:50:07.263127Z","iopub.status.idle":"2025-09-29T13:50:07.483928Z","shell.execute_reply.started":"2025-09-29T13:50:07.263103Z","shell.execute_reply":"2025-09-29T13:50:07.483154Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[tensor([[ 0,  0, 96,  ..., 59,  1, 51],\n         [ 0, 96,  0,  ...,  1, 51, 59],\n         [96,  0, 29,  ..., 51, 59,  1],\n         ...,\n         [69,  1, 70,  ...,  1, 66, 65],\n         [ 1, 70, 55,  ..., 66, 65, 71],\n         [70, 55, 69,  ..., 65, 71, 68]]),\n tensor([[ 0, 96,  0,  ...,  1, 51, 59],\n         [96,  0, 29,  ..., 51, 59,  1],\n         [ 0, 29, 58,  ..., 59,  1, 54],\n         ...,\n         [ 1, 70, 55,  ..., 66, 65, 71],\n         [70, 55, 69,  ..., 65, 71, 68],\n         [55, 69,  1,  ..., 71, 68,  1]])]"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"len(train_dl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:07.484981Z","iopub.execute_input":"2025-09-29T13:50:07.485585Z","iopub.status.idle":"2025-09-29T13:50:07.490383Z","shell.execute_reply.started":"2025-09-29T13:50:07.485553Z","shell.execute_reply":"2025-09-29T13:50:07.489692Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"641"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## Models","metadata":{}},{"cell_type":"markdown","source":"### Training part","metadata":{}},{"cell_type":"code","source":"class CharLSTM(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers=1):\n        super(CharLSTM, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.lstm = nn.LSTM(input_size = embedding_dim, \n                            hidden_size = hidden_size, \n                            num_layers = num_layers, \n                            batch_first=True, dropout = 0.15)\n        self.drop = nn.Dropout(p=0.15)\n        self.ln = nn.LayerNorm(hidden_size)\n        self.fc = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, x, hidden):\n        x = self.drop(self.embedding(x))              # (batch, seq, hidden_size)\n        out, hidden = self.lstm(x, hidden)\n#        out = self.ln(out)\n        out = self.drop(out)\n        logits = self.fc(out)                  \n        return logits, hidden\n\n    def init_hidden(self, batch_size, device):\n        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device = device)\n        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size, device = device)\n        return (h0,c0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:07.491828Z","iopub.execute_input":"2025-09-29T13:50:07.492041Z","iopub.status.idle":"2025-09-29T13:50:07.507285Z","shell.execute_reply.started":"2025-09-29T13:50:07.492025Z","shell.execute_reply":"2025-09-29T13:50:07.506767Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"device1 = torch.device(\"cuda:0\")\ndevice2 = torch.device(\"cuda:1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:07.508067Z","iopub.execute_input":"2025-09-29T13:50:07.508227Z","iopub.status.idle":"2025-09-29T13:50:07.527975Z","shell.execute_reply.started":"2025-09-29T13:50:07.508214Z","shell.execute_reply":"2025-09-29T13:50:07.527443Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"embedding_dim = 128\nhidden_size = 384\nvocab_size = len(mapping)\nnum_epoch = 50\n\nnb_step_train = len(train_dl)\nnb_step_test = len(test_dl)\n\nmodel = CharLSTM(vocab_size, embedding_dim, hidden_size, num_layers=3).to(device1)\nmodel = torch.compile(model)\n\nloss_fn = nn.CrossEntropyLoss(ignore_index = 102)\n\nopti = torch.optim.AdamW(model.parameters(), lr=0.004, weight_decay=1e-4)\nsched_warm = torch.optim.lr_scheduler.LinearLR(opti, start_factor=0.2, end_factor=1.0, total_iters=nb_step_train*4)\nsched_post = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opti, T_0=nb_step_train*5, T_mult=2, eta_min=2e-4) #1 epoch => 2 => 4 => 8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:07.528588Z","iopub.execute_input":"2025-09-29T13:50:07.528824Z","iopub.status.idle":"2025-09-29T13:50:14.982396Z","shell.execute_reply.started":"2025-09-29T13:50:07.528807Z","shell.execute_reply":"2025-09-29T13:50:14.981540Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"list_offset = []\nl_tot = []\n\n#Early stopping\nearly_stopping_count = 0\npatience = 5\n\nbest_val = float(\"inf\")\n\nscaler = torch.amp.GradScaler()\nhid = model.init_hidden(batch_size, device1)\nhid_ = model.init_hidden(batch_size, device1)\n\nfor epoch in range(num_epoch) :\n    #Offset the datas\n    offset = np.random.randint(0, seq_length-1) #Set the offset\n    train_ds.set_offset(offset); test_ds.set_offset(offset)\n\n    model.train();\n    hid = tuple(h.zero_() for h in hid);\n\n    #Create loss per epoch\n    l_train = 0.0\n    l_test = 0.0\n    \n    for X,Y in iter(train_dl) :\n        X = X.to(device1); Y= Y.to(device1, dtype=torch.long)\n        opti.zero_grad(set_to_none=True)\n        \n        #Computation of model\n        hid = tuple(h.detach() for h in hid)\n        \n        with torch.amp.autocast(device_type=\"cuda:0\"):\n            pred, hid = model(X, hid)\n            loss = loss_fn(pred.view(-1, vocab_size), Y.view(-1))\n\n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n        scaler.step(opti) \n        scaler.update()\n        l_train += loss.detach()\n\n        #Scheduler part\n        \n        if sched_post.T_cur == 0 and epoch > 4:  #After warm restart decrease the max learning rate\n            sched_post.base_lrs[0] = sched_post.base_lrs[0] * 0.8\n            sched_post.eta_min = sched_post.eta_min * 1.5\n            print(f\"Decrease {sched_post.base_lrs[0]}, {sched_post.eta_min}\")\n\n        step_scheduler = sched_warm if epoch < 4 else sched_post\n        step_scheduler.step()\n\n    #Test data part\n    \n    model.eval()\n    \n    \n    with torch.inference_mode():\n        hid_ = tuple(h.zero_() for h in hid_);\n        with torch.amp.autocast(\"cuda\"):\n            for X,Y in iter(test_dl) : \n                X = X.to(device1); Y= Y.to(device1, dtype=torch.long)\n                hid_ = tuple(h.detach() for h in hid_)\n                            \n                pred, hid_ = model(X, hid_)\n                loss = loss_fn(pred.view(-1, vocab_size), Y.view(-1))\n                l_test += loss.detach()\n\n        print(epoch,np.exp(l_train.item()/nb_step_train), np.exp(l_test.item()/nb_step_test),\"\\n\")\n     \n        #Record the loss of the epoch\n        l_tot.append(l_test.item()); \n\n        if l_test < best_val :\n            best_val = l_test.item()\n            early_stopping_count = 0\n            torch.save({\n                \"epoch\": epoch,\n                \"model_state_dict\": model._orig_mod.state_dict(),\n                \"optimizer_state_dict\": opti.state_dict(),\n                \"scheduler_state_dict\": sched_post.state_dict(),\n                \"val_loss\": l_test,\n            }, \"model.pt\")\n        \n        elif l_test >= best_val :\n            early_stopping_count += 1\n\n#        if early_stopping_count == patience :\n#            print(\"Early Stopping\")\n#            break \n\nprint(f\"Liste of offset used : {list_offset}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T13:50:14.983219Z","iopub.execute_input":"2025-09-29T13:50:14.983565Z","iopub.status.idle":"2025-09-29T16:43:45.927753Z","shell.execute_reply.started":"2025-09-29T13:50:14.983541Z","shell.execute_reply":"2025-09-29T16:43:45.926434Z"}},"outputs":[{"name":"stdout","text":"0 8.996990051119065 5.589982534819884 \n\n1 5.120284186339614 4.630063708498374 \n\n2 4.461122284941358 4.333786918485035 \n\n3 3.995945358317471 4.086505760633653 \n\n4 3.5734178911286083 3.856873539672058 \n\n5 3.4350564368284466 3.8145723745753175 \n\n6 3.337989358036094 3.78325865404298 \n\n7 3.277555258316564 3.770164860664598 \n\n8 3.252615220890893 3.7598808642026893 \n\nDecrease 0.0032, 0.00030000000000000003\n9 3.2787619986844994 3.7705039356292014 \n\n10 3.2401127950644364 3.769858904775695 \n\n11 3.2208087915452794 3.7680572723581043 \n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/685823406.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0ml_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"14","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T16:43:45.930648Z","iopub.status.idle":"2025-09-29T16:43:45.930918Z","shell.execute_reply.started":"2025-09-29T16:43:45.930810Z","shell.execute_reply":"2025-09-29T16:43:45.930822Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"3.9","metadata":{}}]}