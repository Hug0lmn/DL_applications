{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will serve as a way to train character generation RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:54.473735Z",
     "iopub.status.busy": "2025-09-22T17:55:54.473460Z",
     "iopub.status.idle": "2025-09-22T17:55:58.397706Z",
     "shell.execute_reply": "2025-09-22T17:55:58.397010Z",
     "shell.execute_reply.started": "2025-09-22T17:55:54.473706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:58.399225Z",
     "iopub.status.busy": "2025-09-22T17:55:58.398950Z",
     "iopub.status.idle": "2025-09-22T17:55:58.413350Z",
     "shell.execute_reply": "2025-09-22T17:55:58.412674Z",
     "shell.execute_reply.started": "2025-09-22T17:55:58.399210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/input/rnn-input/Global_mapping.pkl\", \"rb\") as f:\n",
    "    mapping = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:58.414200Z",
     "iopub.status.busy": "2025-09-22T17:55:58.413958Z",
     "iopub.status.idle": "2025-09-22T17:55:58.423995Z",
     "shell.execute_reply": "2025-09-22T17:55:58.423240Z",
     "shell.execute_reply.started": "2025-09-22T17:55:58.414176Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '%', 5: '&', 6: \"'\", 7: '+', 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: ';', 24: '<', 25: '>', 26: '?', 27: 'A', 28: 'B', 29: 'C', 30: 'D', 31: 'E', 32: 'F', 33: 'G', 34: 'H', 35: 'I', 36: 'J', 37: 'K', 38: 'L', 39: 'M', 40: 'N', 41: 'O', 42: 'P', 43: 'Q', 44: 'R', 45: 'S', 46: 'T', 47: 'U', 48: 'V', 49: 'W', 50: 'X', 51: 'Y', 52: 'Z', 53: 'a', 54: 'b', 55: 'c', 56: 'd', 57: 'e', 58: 'f', 59: 'g', 60: 'h', 61: 'i', 62: 'j', 63: 'k', 64: 'l', 65: 'm', 66: 'n', 67: 'o', 68: 'p', 69: 'q', 70: 'r', 71: 's', 72: 't', 73: 'u', 74: 'v', 75: 'w', 76: 'x', 77: 'y', 78: 'z', 79: '§', 80: 'À', 81: 'Ç', 82: 'É', 83: 'Ê', 84: 'Î', 85: 'Ô', 86: 'Ö', 87: 'Ü', 88: 'à', 89: 'á', 90: 'â', 91: 'ã', 92: 'ä', 93: 'æ', 94: 'ç', 95: 'è', 96: 'é', 97: 'ê', 98: 'ë', 99: 'í', 100: 'î', 101: 'ï', 102: 'ñ', 103: 'ô', 104: 'ö', 105: 'ù', 106: 'û', 107: 'ü', 108: 'Ā', 109: 'ā', 110: 'ğ', 111: 'ō', 112: 'Œ', 113: 'œ', 114: 'Ş', 115: 'ş', 116: 'ū', 117: '\\u205f'}\n"
     ]
    }
   ],
   "source": [
    "# Decode\n",
    "int2char = {i: ch for ch, i in mapping.items()}\n",
    "print(int2char)\n",
    "\n",
    "nb_char = len(int2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the randomness during the training :\n",
    "\n",
    "For each epoch the entire corpus will have a random specific offset value in order that the model during training doesn't see the exact same text during X epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:58.425108Z",
     "iopub.status.busy": "2025-09-22T17:55:58.424771Z",
     "iopub.status.idle": "2025-09-22T17:55:58.435455Z",
     "shell.execute_reply": "2025-09-22T17:55:58.434694Z",
     "shell.execute_reply.started": "2025-09-22T17:55:58.425085Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CharDataset(Dataset) :\n",
    "    def __init__(self,text,length_seq) :\n",
    "        self.text = text\n",
    "        self.length_seq = length_seq\n",
    "        self.max_start = len(self.text) - length_seq - 1\n",
    "        self.offset = 0\n",
    "        \n",
    "    def set_offset(self, offset) :\n",
    "        self.offset = offset\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return self.max_start\n",
    "\n",
    "    def __getitem__(self, i) :\n",
    "        s = (i + self.offset) % self.max_start\n",
    "        x = torch.from_numpy(self.text[s:s+self.length_seq])\n",
    "        y = torch.from_numpy(self.text[s+1:s+self.length_seq+1])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:58.438319Z",
     "iopub.status.busy": "2025-09-22T17:55:58.438129Z",
     "iopub.status.idle": "2025-09-22T17:55:58.457212Z",
     "shell.execute_reply": "2025-09-22T17:55:58.456502Z",
     "shell.execute_reply.started": "2025-09-22T17:55:58.438304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seq_length = 250\n",
    "dataset_ = np.load(\"/kaggle/input/rnn-input/corpus_encoded.npy\",\"r\")\n",
    "len_train = int(len(dataset_)*0.9)\n",
    "train = dataset_[:len_train]\n",
    "test = dataset_[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:58.458001Z",
     "iopub.status.busy": "2025-09-22T17:55:58.457808Z",
     "iopub.status.idle": "2025-09-22T17:55:58.461563Z",
     "shell.execute_reply": "2025-09-22T17:55:58.460946Z",
     "shell.execute_reply.started": "2025-09-22T17:55:58.457986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_ds = CharDataset(train,length_seq=250)\n",
    "test_ds = CharDataset(test,length_seq=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:58.462542Z",
     "iopub.status.busy": "2025-09-22T17:55:58.462317Z",
     "iopub.status.idle": "2025-09-22T17:55:58.509527Z",
     "shell.execute_reply": "2025-09-22T17:55:58.508756Z",
     "shell.execute_reply.started": "2025-09-22T17:55:58.462521Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24, 28, 31, 33, 35, 40, 40, 35, 40, 33, 25,  0, 24, 29, 41, 47, 42, 38,\n",
      "        31, 46, 25,  0, 36,  6, 53, 61, 65, 57,  1, 68, 53, 71,  1, 64, 57, 71,\n",
      "         1, 54, 57, 73, 70, 57, 72, 72, 57, 71,  1, 56, 67, 66, 55,  1, 58, 53,\n",
      "        73, 72,  1, 69, 73,  6, 55, 57, 71,  1, 68, 67, 73, 58, 58, 61, 53, 71,\n",
      "        71, 57, 71,  1, 65,  6, 57, 66, 72, 57, 66, 56, 57, 66, 72,  0, 51,  1,\n",
      "        53,  1, 69, 73,  6, 56, 53, 66, 71,  1, 27, 64, 53, 56, 56, 61, 66,  1,\n",
      "        69, 73, 57,  1, 72,  6, 57, 66,  1, 74, 57, 70, 70, 53, 71,  1, 73, 66,\n",
      "        57,  1, 63, 61, 58, 58, 57, 70,  1, 71, 73, 70,  1, 73, 66,  1, 65, 57,\n",
      "        66, 56, 61, 53, 66, 72,  0, 51,  1, 53,  1, 68, 64, 73, 71,  1, 56,  6,\n",
      "        70, 57, 71, 68, 57, 55, 72,  1, 57, 66, 72, 70, 57,  1, 64, 57, 71,  1,\n",
      "        56, 53, 70, 67, 66, 66, 57, 71,  8,  1, 64, 57, 71,  1, 68, 57, 72, 61,\n",
      "        72, 57, 71,  1, 56,  6, 13, 18,  1, 68, 61, 59, 57, 71,  0, 40, 67, 70,\n",
      "        65, 53, 64,  1, 69, 73, 57,  1, 64, 57, 71,  1, 68, 57, 72, 61, 72, 57,\n",
      "        71,  1, 58, 57, 71, 71, 57, 71,  1, 55, 64, 57, 53, 66,  0, 45])\n",
      "<BEGINNING>\n",
      "<COUPLET>\n",
      "J'aime pas les beurettes donc faut qu'ces pouffiasses m'entendent\n",
      "Y a qu'dans Aladdin que t'en verras une kiffer sur un mendiant\n",
      "Y a plus d'respect entre les daronnes, les petites d'16 piges\n",
      "Normal que les petites fesses clean\n",
      "S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/303235149.py:16: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "  x = torch.from_numpy(self.text[s:s+self.length_seq])\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[0][0])\n",
    "print(\"\".join([int2char[i] for i in train_ds[0][0][:seq_length].numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Dataloader and co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "200 context for previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:58.510563Z",
     "iopub.status.busy": "2025-09-22T17:55:58.510316Z",
     "iopub.status.idle": "2025-09-22T17:55:58.516241Z",
     "shell.execute_reply": "2025-09-22T17:55:58.515464Z",
     "shell.execute_reply.started": "2025-09-22T17:55:58.510542Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, pin_memory=True, pin_memory_device=\"cuda:0\", \n",
    "                        num_workers=4, prefetch_factor=4, shuffle=False, drop_last=True) #Shuffle False because we need the RNN to use previous sequences data to predict next one\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, pin_memory=True, pin_memory_device=\"cuda:0\", \n",
    "                       num_workers=2, prefetch_factor=2, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the good dataloading and offset validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:58.517777Z",
     "iopub.status.busy": "2025-09-22T17:55:58.517192Z",
     "iopub.status.idle": "2025-09-22T17:55:58.962029Z",
     "shell.execute_reply": "2025-09-22T17:55:58.961188Z",
     "shell.execute_reply.started": "2025-09-22T17:55:58.517755Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 28, 31,  ..., 66,  0, 45],\n",
      "        [28, 31, 33,  ...,  0, 45, 57],\n",
      "        [31, 33, 35,  ..., 45, 57,  1],\n",
      "        ...,\n",
      "        [57,  1, 68,  ...,  1, 73, 66],\n",
      "        [ 1, 68, 70,  ..., 73, 66,  1],\n",
      "        [68, 70, 61,  ..., 66,  1, 71]])\n"
     ]
    }
   ],
   "source": [
    "for i in train_dl :\n",
    "    print(i[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:58.963378Z",
     "iopub.status.busy": "2025-09-22T17:55:58.963072Z",
     "iopub.status.idle": "2025-09-22T17:55:59.116437Z",
     "shell.execute_reply": "2025-09-22T17:55:59.115596Z",
     "shell.execute_reply.started": "2025-09-22T17:55:58.963330Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[28, 31, 33,  ...,  0, 45, 57],\n",
       "         [31, 33, 35,  ..., 45, 57,  1],\n",
       "         [33, 35, 40,  ..., 57,  1, 68],\n",
       "         ...,\n",
       "         [ 1, 68, 70,  ..., 73, 66,  1],\n",
       "         [68, 70, 61,  ..., 66,  1, 71],\n",
       "         [70, 61, 71,  ...,  1, 71, 55]]),\n",
       " tensor([[31, 33, 35,  ..., 45, 57,  1],\n",
       "         [33, 35, 40,  ..., 57,  1, 68],\n",
       "         [35, 40, 40,  ...,  1, 68, 70],\n",
       "         ...,\n",
       "         [68, 70, 61,  ..., 66,  1, 71],\n",
       "         [70, 61, 71,  ...,  1, 71, 55],\n",
       "         [61, 71, 67,  ..., 71, 55, 60]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.set_offset(1)\n",
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:59.117727Z",
     "iopub.status.busy": "2025-09-22T17:55:59.117460Z",
     "iopub.status.idle": "2025-09-22T17:55:59.123048Z",
     "shell.execute_reply": "2025-09-22T17:55:59.122222Z",
     "shell.execute_reply.started": "2025-09-22T17:55:59.117704Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:59.124101Z",
     "iopub.status.busy": "2025-09-22T17:55:59.123876Z",
     "iopub.status.idle": "2025-09-22T17:55:59.134754Z",
     "shell.execute_reply": "2025-09-22T17:55:59.134109Z",
     "shell.execute_reply.started": "2025-09-22T17:55:59.124077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=1):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, num_layers, batch_first=True, dropout = 0.15, nonlinearity =\"relu\")\n",
    "        self.drop = nn.Dropout(p=0.15)\n",
    "        self.ln = nn.LayerNorm(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)              # (batch, seq, hidden_size)\n",
    "        x = self.drop(x)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = self.ln(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc(out)                  \n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "#        return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return torch.randn(self.num_layers, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:59.135936Z",
     "iopub.status.busy": "2025-09-22T17:55:59.135631Z",
     "iopub.status.idle": "2025-09-22T17:55:59.148340Z",
     "shell.execute_reply": "2025-09-22T17:55:59.147508Z",
     "shell.execute_reply.started": "2025-09-22T17:55:59.135895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device1 = torch.device(\"cuda:0\")\n",
    "device2 = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:55:59.151032Z",
     "iopub.status.busy": "2025-09-22T17:55:59.150817Z",
     "iopub.status.idle": "2025-09-22T17:56:01.836998Z",
     "shell.execute_reply": "2025-09-22T17:56:01.836211Z",
     "shell.execute_reply.started": "2025-09-22T17:55:59.151016Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(int2char)\n",
    "hidden_size = 250\n",
    "num_epoch = 100\n",
    "\n",
    "nb_step_train = len(train_dl)\n",
    "nb_step_test = len(test_dl)\n",
    "\n",
    "model = CharRNN(vocab_size, hidden_size, num_layers=3)   \n",
    "\n",
    "model.to(device1)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "opti = torch.optim.AdamW(model.parameters(), lr=0.0015, weight_decay=1e-3)\n",
    "sched_warm = torch.optim.lr_scheduler.LinearLR(opti, start_factor=0.2, end_factor=1.0, total_iters=nb_step_train)\n",
    "sched_post = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opti, T_0=len(train_dl)*10, T_mult=2, eta_min=0.0001) #1 epoch => 2 => 4 => 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-22T17:56:01.838171Z",
     "iopub.status.busy": "2025-09-22T17:56:01.837785Z",
     "iopub.status.idle": "2025-09-22T20:52:27.172034Z",
     "shell.execute_reply": "2025-09-22T20:52:27.170857Z",
     "shell.execute_reply.started": "2025-09-22T17:56:01.838142Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.213998203017805 \n",
      "\n",
      "1 5.102510106735906 \n",
      "\n",
      "2 4.956317091198305 \n",
      "\n",
      "3 4.770973074054662 \n",
      "\n",
      "4 4.708132925428319 \n",
      "\n",
      "5 4.657053951892793 \n",
      "\n",
      "6 4.619699820159317 \n",
      "\n",
      "7 4.5934330493870545 \n",
      "\n",
      "8 4.579322688367851 \n",
      "\n",
      "9 4.573801917823297 \n",
      "\n",
      "10 4.571850364942143 \n",
      "\n",
      "Decrease 0.0009, 0.000125\n",
      "11 4.571408687727923 \n",
      "\n",
      "12 4.5476968784192815 \n",
      "\n",
      "13 4.52594190559593 \n",
      "\n",
      "14 4.504352967062929 \n",
      "\n",
      "15 4.4835319505337985 \n",
      "\n",
      "16 4.465478933123772 \n",
      "\n",
      "17 4.451887632472756 \n",
      "\n",
      "18 4.437950322360753 \n",
      "\n",
      "19 4.424950749387633 \n",
      "\n",
      "20 4.414524484453296 \n",
      "\n",
      "21 4.406728053109271 \n",
      "\n",
      "22 4.396226549763397 \n",
      "\n",
      "23 4.3889988618282985 \n",
      "\n",
      "24 4.381038298683579 \n",
      "\n",
      "25 4.3769592717581505 \n",
      "\n",
      "26 4.372171215927915 \n",
      "\n",
      "27 4.368648199114715 \n",
      "\n",
      "28 4.367300004398819 \n",
      "\n",
      "29 4.365718202070801 \n",
      "\n",
      "30 4.363397283750461 \n",
      "\n",
      "Decrease 0.00054, 0.00015625\n",
      "31 4.369227802078988 \n",
      "\n",
      "32 4.362731532957022 \n",
      "\n",
      "33 4.357066072132486 \n",
      "\n",
      "34 4.349843614841055 \n",
      "\n",
      "35 4.345079037963747 \n",
      "\n",
      "36 4.340306640244396 \n",
      "\n",
      "37 4.3328070781560895 \n",
      "\n",
      "38 4.328477958927817 \n",
      "\n",
      "39 4.321076042924992 \n",
      "\n",
      "40 4.3163429764467 \n",
      "\n",
      "41 4.313787734999694 \n",
      "\n",
      "42 4.309388353315077 \n",
      "\n",
      "43 4.304414208904541 \n",
      "\n",
      "44 4.300992034806654 \n",
      "\n",
      "45 4.302839534688347 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36/1858037363.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0ml_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_offset = []\n",
    "l_tot = []\n",
    "\n",
    "#Early stopping\n",
    "early_stopping_count = 0\n",
    "patience = 5\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "hid = model.init_hidden(batch_size).to(device1)\n",
    "\n",
    "hid_ = model.init_hidden(batch_size).to(device1)\n",
    "\n",
    "for epoch in range(num_epoch) :\n",
    "    \n",
    "    offset = np.random.randint(0, seq_length-1) #Set the offset\n",
    "    list_offset.append(offset) #Keep in memory\n",
    "\n",
    "    #Offset the datas\n",
    "    train_ds.set_offset(offset); test_ds.set_offset(offset)\n",
    "\n",
    "    model.train();\n",
    "    hid.zero_();\n",
    "\n",
    "    #Create loss per epoch\n",
    "    l_train = 0.0\n",
    "    l_test = 0.0\n",
    "    \n",
    "    for X,Y in iter(train_dl) :\n",
    "        X = X.to(device1); Y= Y.to(device1)\n",
    "        opti.zero_grad(set_to_none=True)\n",
    "        \n",
    "        #Computation of model\n",
    "        hid = hid.detach();\n",
    "        \n",
    "        with torch.amp.autocast(device_type=\"cuda:0\"):\n",
    "            pred, hid = model(X, hid)\n",
    "            loss = loss_fn(pred.view(-1, vocab_size), Y.view(-1))\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "        scaler.step(opti); scaler.update()\n",
    "        l_train += loss.detach()\n",
    "\n",
    "        #Scheduler part\n",
    "        #Warm start\n",
    "        \n",
    "        if sched_post.T_cur == 0 and epoch > 1:  #After warm restart decrease the max learning rate\n",
    "            sched_post.base_lrs[0] = sched_post.base_lrs[0] * 0.6\n",
    "            sched_post.eta_min = sched_post.eta_min * 1.25\n",
    "            print(f\"Decrease {sched_post.base_lrs[0]}, {sched_post.eta_min}\")\n",
    "\n",
    "        step_scheduler = sched_warm if epoch == 0 else sched_post\n",
    "        step_scheduler.step()\n",
    "\n",
    "    #Test data part\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        hid_.zero_()  \n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            for X,Y in iter(test_dl) : \n",
    "                X = X.to(device1); Y= Y.to(device1)\n",
    "                hid_ = hid_.detach()\n",
    "                            \n",
    "                pred, hid_ = model(X, hid_)\n",
    "                loss = loss_fn(pred.view(-1, vocab_size), Y.view(-1))\n",
    "                l_test += loss.detach()\n",
    "\n",
    "        print(epoch,np.exp(l_test.item()/nb_step_test),\"\\n\")\n",
    "     \n",
    "        #Record the loss of the epoch\n",
    "        l_tot.append(l_test.item()); \n",
    "\n",
    "        if l_test < best_val :\n",
    "            best_val = l_test.item()\n",
    "            early_stopping_count = 0\n",
    "            torch.save({\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": opti.state_dict(),\n",
    "                \"scheduler_state_dict\": sched_post.state_dict(),\n",
    "                \"val_loss\": l_test,\n",
    "            }, \"model\")\n",
    "        \n",
    "        elif l_test >= best_val :\n",
    "            early_stopping_count += 1\n",
    "\n",
    "        if early_stopping_count == patience :\n",
    "            print(\"Early Stopping\")\n",
    "            break \n",
    "\n",
    "print(f\"Liste of offset used : {list_offset}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8091998,
     "sourceId": 12798610,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8138327,
     "sourceId": 12977125,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8299981,
     "sourceId": 13102904,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
